{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "84552f94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84552f94",
        "outputId": "967bd7a2-83f2-4c06-cbd4-1cc6932feec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50 saved to data/models/resnet50.pth\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 50.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2 saved to data/models/mobilenet_v2.pth\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Buat direktori jika belum ada\n",
        "model_dir = \"data/models/\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Cek dan download ResNet50 jika belum ada\n",
        "resnet_path = os.path.join(model_dir, \"resnet50.pth\")\n",
        "if not os.path.exists(resnet_path):\n",
        "    resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "    torch.save(resnet.state_dict(), resnet_path)\n",
        "    print(f\"ResNet50 saved to {resnet_path}\")\n",
        "else:\n",
        "    print(f\"ResNet50 already exists at {resnet_path}, skipping download.\")\n",
        "\n",
        "# Cek dan download MobileNetV2 jika belum ada\n",
        "mobilenet_path = os.path.join(model_dir, \"mobilenet_v2.pth\")\n",
        "if not os.path.exists(mobilenet_path):\n",
        "    mobilenet = models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
        "    torch.save(mobilenet.state_dict(), mobilenet_path)\n",
        "    print(f\"MobileNetV2 saved to {mobilenet_path}\")\n",
        "else:\n",
        "    print(f\"MobileNetV2 already exists at {mobilenet_path}, skipping download.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e4dff85",
      "metadata": {
        "id": "8e4dff85"
      },
      "source": [
        "# Fungsi Load dan Save Bobot Model (PyTorch/NumPy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e1158e7",
      "metadata": {
        "id": "2e1158e7"
      },
      "source": [
        "### Fungsi untuk PyTorch (.pth atau .pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62220133",
      "metadata": {
        "id": "62220133"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def load_model_weights(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Memuat state_dict (bobot) dari file PyTorch (.pth atau .pt).\n",
        "\n",
        "    Args:\n",
        "        file_path: Path menuju file bobot model.\n",
        "\n",
        "    Returns:\n",
        "        dict: State dictionary (nama lapisan -> tensor bobot).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Gunakan torch.load untuk memuat state_dict.\n",
        "        # map_location='cpu' disarankan untuk memastikan kompatibilitas antar lingkungan.\n",
        "        state_dict = torch.load(file_path, map_location='cpu')\n",
        "\n",
        "        # Asumsi: File .pth berisi state_dict saja.\n",
        "        # Jika file berisi model lengkap, Anda mungkin perlu memuat arsitektur terlebih dahulu.\n",
        "        return state_dict\n",
        "    except Exception as e:\n",
        "        print(f\"Error memuat file PyTorch {file_path}: {e}\")\n",
        "        return {}\n",
        "\n",
        "def save_model_weights(state_dict: dict, file_path: str):\n",
        "    \"\"\"\n",
        "    Menyimpan state_dict bobot (setelah dimanipulasi) ke file PyTorch.\n",
        "\n",
        "    Args:\n",
        "        state_dict: Dictionary bobot yang telah dimodifikasi (hasil dari inject_lsb).\n",
        "        file_path: Path tujuan untuk menyimpan file bobot baru.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        torch.save(state_dict, file_path)\n",
        "        print(f\"Bobot model berhasil disimpan ke {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error menyimpan file PyTorch ke {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e77f02b0",
      "metadata": {
        "id": "e77f02b0"
      },
      "source": [
        "###  Fungsi Alternatif untuk NumPy (.npy atau .npz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5d0a326b",
      "metadata": {
        "id": "5d0a326b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_numpy_array(file_path: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Memuat array bobot tunggal dari file NumPy (.npy).\n",
        "\n",
        "    Args:\n",
        "        file_path: Path menuju file .npy.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array bobot yang dimuat.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        weights = np.load(file_path)\n",
        "        return weights\n",
        "    except Exception as e:\n",
        "        print(f\"Error memuat file NumPy {file_path}: {e}\")\n",
        "        return np.array([])\n",
        "\n",
        "def save_numpy_array(weights_array: np.ndarray, file_path: str):\n",
        "    \"\"\"\n",
        "    Menyimpan array bobot (setelah dimanipulasi) ke file NumPy.\n",
        "\n",
        "    Args:\n",
        "        weights_array: Array bobot yang telah dimodifikasi.\n",
        "        file_path: Path tujuan untuk menyimpan file bobot baru (.npy).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        np.save(file_path, weights_array)\n",
        "        print(f\"Array bobot berhasil disimpan ke {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error menyimpan file NumPy ke {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce5e153a",
      "metadata": {
        "id": "ce5e153a"
      },
      "source": [
        "# LSB Inject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b481b1b0",
      "metadata": {
        "id": "b481b1b0"
      },
      "outputs": [],
      "source": [
        "def inject_lsb(model_weights: dict, payload_size_bits: int, target_bit: int) -> dict:\n",
        "    \"\"\"\n",
        "    Menyuntikkan payload biner acak ke posisi bit LSB yang ditentukan\n",
        "    (misalnya, target_bit=0 untuk LSB pertama mantissa).\n",
        "    \"\"\"\n",
        "    stego_weights = {}\n",
        "    payload = np.random.randint(0, 2, payload_size_bits) # Payload biner acak\n",
        "    payload_index = 0\n",
        "\n",
        "    for name, tensor in model_weights.items():\n",
        "        if tensor.dtype != torch.float32: # Pastikan hanya bobot float32 yang dimodifikasi\n",
        "            stego_weights[name] = tensor\n",
        "            continue\n",
        "\n",
        "        # Konversi tensor float32 ke representasi biner (NumPy diperlukan)\n",
        "        weights_flat = tensor.cpu().numpy().flatten()\n",
        "        weights_view = weights_flat.view(np.int32)\n",
        "\n",
        "        # Masking dan penyuntikan LSB\n",
        "        for i in range(len(weights_view)):\n",
        "            if payload_index < payload_size_bits:\n",
        "                # Dapatkan nilai integer 32-bit dari float\n",
        "                int_val = weights_view[i]\n",
        "\n",
        "                # Buat mask untuk menargetkan bit ke-target_bit (misal: 1 << target_bit)\n",
        "                mask = 1 << target_bit\n",
        "\n",
        "                # Hapus bit lama dan sisipkan bit payload baru\n",
        "                # Posisi LSB untuk mantissa float32 adalah 0 sampai 22\n",
        "\n",
        "                new_bit = payload[payload_index]\n",
        "\n",
        "                # Hapus bit lama:\n",
        "                int_val &= ~mask\n",
        "\n",
        "                # Sisipkan bit baru:\n",
        "                int_val |= (new_bit << target_bit)\n",
        "\n",
        "                weights_view[i] = int_val\n",
        "                payload_index += 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # Konversi kembali ke tensor dan simpan\n",
        "        weights_flat_new = weights_view.view(np.float32)\n",
        "        stego_weights[name] = torch.from_numpy(weights_flat_new.reshape(tensor.shape)).to(tensor.device)\n",
        "\n",
        "        if payload_index >= payload_size_bits:\n",
        "            break\n",
        "\n",
        "    return stego_weights, payload_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4946c758",
      "metadata": {
        "id": "4946c758"
      },
      "source": [
        "# Generation Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a448751",
      "metadata": {
        "id": "1a448751"
      },
      "source": [
        "### *Load Models*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0d59b785",
      "metadata": {
        "id": "0d59b785"
      },
      "outputs": [],
      "source": [
        "\n",
        "weights_cover = load_model_weights(f\"{model_dir}/resnet50.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff890b1",
      "metadata": {
        "id": "fff890b1"
      },
      "source": [
        "### *LSB Inject*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "331bb3b4",
      "metadata": {
        "id": "331bb3b4"
      },
      "outputs": [],
      "source": [
        "def decimal_to_short(n):\n",
        "    \"\"\"\n",
        "    Mengkonversi angka desimal ke format singkat, misal:\n",
        "    1000 -> '1k', 1000000 -> '1M', 1500 -> '1.5k'\n",
        "    \"\"\"\n",
        "    if n >= 1_000_000_000:\n",
        "        return f\"{n/1_000_000_000:.1f}B\".rstrip('0').rstrip('.')\n",
        "    elif n >= 1_000_000:\n",
        "        return f\"{n/1_000_000:.1f}M\".rstrip('0').rstrip('.')\n",
        "    elif n >= 1_000:\n",
        "        return f\"{n/1_000:.1f}k\".rstrip('0').rstrip('.')\n",
        "    else:\n",
        "        return str(n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d150a5f0",
      "metadata": {
        "id": "d150a5f0"
      },
      "outputs": [],
      "source": [
        "targetBit = 0\n",
        "payloadSizeBits=500000\n",
        "weights_stego, bits_injected = inject_lsb(weights_cover, payload_size_bits=payloadSizeBits, target_bit=targetBit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4832a0",
      "metadata": {
        "id": "fb4832a0"
      },
      "source": [
        "### *Save Stego Models*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3eaf0486",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eaf0486",
        "outputId": "6837784a-4d9a-4003-d525-0d9d74b14078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bobot model berhasil disimpan ke data/models//ResNet50_stego_0_500.0k.pth\n"
          ]
        }
      ],
      "source": [
        "save_model_weights(weights_stego, f\"{model_dir}/ResNet50_stego_{targetBit}_{decimal_to_short(payloadSizeBits)}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691c0a91",
      "metadata": {
        "id": "691c0a91"
      },
      "outputs": [],
      "source": [
        "print(weights_cover)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff5d73b",
      "metadata": {
        "id": "1ff5d73b"
      },
      "outputs": [],
      "source": [
        "print(weights_stego)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba9309ef",
      "metadata": {
        "id": "ba9309ef"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "91dc5bd0",
      "metadata": {
        "id": "91dc5bd0"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from scipy.stats import entropy\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8be890",
      "metadata": {
        "id": "1d8be890"
      },
      "source": [
        "#### *1. Ekstraksi Loss & Gradient (Memerlukan Model DL)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e0c15298",
      "metadata": {
        "id": "e0c15298"
      },
      "outputs": [],
      "source": [
        "def extract_loss_gradient(model: nn.Module, ae_model: nn.Module, data_input: torch.Tensor) -> tuple:\n",
        "    \"\"\"\n",
        "    Menghitung Reconstruction Loss (Skalar) dan Gradient (Vektor/Skalar)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Fitur Reconstruction Loss\n",
        "    weight_tensor_flat = torch.cat([w.flatten() for w in model.parameters()])\n",
        "    reconstructed_weights = ae_model(weight_tensor_flat)\n",
        "    loss_reconstruction = mean_squared_error(weight_tensor_flat.detach().cpu().numpy(),\n",
        "                                            reconstructed_weights.detach().cpu().numpy())\n",
        "\n",
        "    # 2. Fitur Gradient\n",
        "    # Asumsi: Menggunakan CrossEntropyLoss pada satu sampel input\n",
        "    target = torch.tensor([0]) # Placeholder target class\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Hitung loss dan backpropagate untuk mendapatkan gradien\n",
        "    output = model(data_input)\n",
        "    loss_grad = criterion(output, target)\n",
        "    loss_grad.backward()\n",
        "\n",
        "    # Ekstraksi Gradien (ambil norm L2 sebagai fitur skalar, atau flatten sebagai vektor)\n",
        "    gradients = [w.grad.flatten() for w in model.parameters() if w.grad is not None]\n",
        "    gradient_vector = torch.cat(gradients).detach().cpu().numpy()\n",
        "\n",
        "    # Menggunakan L2 norm sebagai fitur skalar untuk simplifikasi\n",
        "    gradient_norm = np.linalg.norm(gradient_vector)\n",
        "\n",
        "    return loss_reconstruction, gradient_norm # Atau kembalikan gradient_vector jika PSO bisa menangani dimensi besar"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2086208",
      "metadata": {
        "id": "d2086208"
      },
      "source": [
        "#### *2. Ekstraksi Entropi Bit-plane (Memerlukan NumPy)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5458031a",
      "metadata": {
        "id": "5458031a"
      },
      "outputs": [],
      "source": [
        "def extract_bitplane_entropy(model_weights: dict) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Menghitung Entropi Shannon untuk 23 bit-plane mantissa (float32)\n",
        "    \"\"\"\n",
        "    entropy_vector = np.zeros(23)\n",
        "\n",
        "    # Kumpulkan semua bobot float32 ke dalam satu array besar\n",
        "    all_float_weights = np.concatenate([t.cpu().numpy().flatten()\n",
        "                                        for t in model_weights.values()\n",
        "                                        if t.dtype == torch.float32])\n",
        "\n",
        "    # Konversi ke representasi integer 32-bit\n",
        "    weights_int_view = all_float_weights.view(np.int32)\n",
        "\n",
        "    # Analisis Bit-Plane (Mantissa adalah bit ke-0 hingga ke-22)\n",
        "    for j in range(23):\n",
        "        # Ekstraksi bit-plane j: (int_value >> j) & 1\n",
        "        bit_plane = (weights_int_view >> j) & 1\n",
        "\n",
        "        # Hitung probabilitas p0 dan p1\n",
        "        p1 = np.mean(bit_plane)\n",
        "        p0 = 1.0 - p1\n",
        "\n",
        "        # Hitung Entropi Shannon H = - (p0*log2(p0) + p1*log2(p1))\n",
        "        # Gunakan np.clip untuk menghindari log(0)\n",
        "        h = shannon_entropy([p0, p1], base=2)\n",
        "        entropy_vector[j] = h\n",
        "\n",
        "    return entropy_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed468e28",
      "metadata": {
        "id": "ed468e28"
      },
      "source": [
        "#### *3. Penggabungan Fitur*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d7bdce3c",
      "metadata": {
        "id": "d7bdce3c"
      },
      "outputs": [],
      "source": [
        "#Load weights cover models\n",
        "weights_cover_model = load_model_weights(f\"{model_dir}/resnet50.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a65860d4",
      "metadata": {
        "id": "a65860d4"
      },
      "outputs": [],
      "source": [
        "#Load weights stego models\n",
        "weights_stego_model = load_model_weights(f\"{model_dir}/ResNet50_stego_0_100.0k.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2833d50d",
      "metadata": {
        "id": "2833d50d"
      },
      "outputs": [],
      "source": [
        "# F_combined = [loss_reconstruction] + [gradient_norm] + F_Ent\n",
        "# F_combined adalah Vektor Fitur Berdimensi Tinggi yang menjadi input untuk PSO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49df77fd",
      "metadata": {
        "id": "49df77fd"
      },
      "source": [
        "#### *Train Autoencoder*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b6e9bd64",
      "metadata": {
        "id": "b6e9bd64"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class WeightAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(WeightAutoencoder, self).__init__()\n",
        "        # Encoder: Mengurangi dimensi ke hidden_dim (ruang laten)\n",
        "        hidden_dim = input_dim // 100 # Reduksi drastis untuk kompresi\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim // 2, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Decoder: Merekonstruksi dimensi kembali ke input_dim\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, input_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim // 2, input_dim),\n",
        "            nn.Sigmoid() # Atau ReLU, tergantung rentang bobot\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9e855edd",
      "metadata": {
        "id": "9e855edd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_autoencoder(cover_weights_list: list, epochs: int = 50, batch_size: int = 32) -> WeightAutoencoder:\n",
        "    \"\"\"\n",
        "    Melatih Autoencoder hanya pada bobot model 'Cover' untuk pembelajaran normal.\n",
        "\n",
        "    Args:\n",
        "        cover_weights_list: List dari vektor bobot yang sudah diratakan dari semua model Cover.\n",
        "        epochs: Jumlah iterasi pelatihan.\n",
        "        batch_size: Ukuran batch.\n",
        "\n",
        "    Returns:\n",
        "        WeightAutoencoder: Model Autoencoder yang telah dilatih.\n",
        "    \"\"\"\n",
        "    if not cover_weights_list:\n",
        "        raise ValueError(\"Daftar bobot model Cover tidak boleh kosong.\")\n",
        "\n",
        "    # 1. Persiapan Data\n",
        "    # Menggabungkan semua bobot Cover menjadi satu tensor matriks\n",
        "    weights_tensor = torch.stack([torch.tensor(w, dtype=torch.float32) for w in cover_weights_list])\n",
        "    input_dim = weights_tensor.shape[1]\n",
        "\n",
        "    # Split data untuk validasi\n",
        "    X_train, X_val = train_test_split(weights_tensor, test_size=0.1, random_state=42)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, X_train) # Input = Output\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # 2. Inisialisasi Model dan Optimizer\n",
        "    ae_model = WeightAutoencoder(input_dim)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(ae_model.parameters(), lr=0.001)\n",
        "\n",
        "    # 3. Loop Pelatihan\n",
        "    ae_model.train()\n",
        "    print(f\"Memulai pelatihan Autoencoder. Dimensi input: {input_dim}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for data in train_loader:\n",
        "            inputs, _ = data\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = ae_model(inputs)\n",
        "            loss = criterion(outputs, inputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_dataset)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
        "\n",
        "        # Tambahkan logika validasi (X_val) di sini jika diperlukan\n",
        "\n",
        "    # 4. Simpan Model Terlatih\n",
        "    torch.save(ae_model.state_dict(), \"trained_autoencoder_weights.pth\")\n",
        "    return ae_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0170b69c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0170b69c",
        "outputId": "69defe39-29c4-473a-c820-8d230bbe1946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daftar layer pada model (dict keys):\n",
            "conv1.weight\n",
            "bn1.weight\n",
            "bn1.bias\n",
            "bn1.running_mean\n",
            "bn1.running_var\n",
            "bn1.num_batches_tracked\n",
            "layer1.0.conv1.weight\n",
            "layer1.0.bn1.weight\n",
            "layer1.0.bn1.bias\n",
            "layer1.0.bn1.running_mean\n",
            "layer1.0.bn1.running_var\n",
            "layer1.0.bn1.num_batches_tracked\n",
            "layer1.0.conv2.weight\n",
            "layer1.0.bn2.weight\n",
            "layer1.0.bn2.bias\n",
            "layer1.0.bn2.running_mean\n",
            "layer1.0.bn2.running_var\n",
            "layer1.0.bn2.num_batches_tracked\n",
            "layer1.0.conv3.weight\n",
            "layer1.0.bn3.weight\n",
            "layer1.0.bn3.bias\n",
            "layer1.0.bn3.running_mean\n",
            "layer1.0.bn3.running_var\n",
            "layer1.0.bn3.num_batches_tracked\n",
            "layer1.0.downsample.0.weight\n",
            "layer1.0.downsample.1.weight\n",
            "layer1.0.downsample.1.bias\n",
            "layer1.0.downsample.1.running_mean\n",
            "layer1.0.downsample.1.running_var\n",
            "layer1.0.downsample.1.num_batches_tracked\n",
            "layer1.1.conv1.weight\n",
            "layer1.1.bn1.weight\n",
            "layer1.1.bn1.bias\n",
            "layer1.1.bn1.running_mean\n",
            "layer1.1.bn1.running_var\n",
            "layer1.1.bn1.num_batches_tracked\n",
            "layer1.1.conv2.weight\n",
            "layer1.1.bn2.weight\n",
            "layer1.1.bn2.bias\n",
            "layer1.1.bn2.running_mean\n",
            "layer1.1.bn2.running_var\n",
            "layer1.1.bn2.num_batches_tracked\n",
            "layer1.1.conv3.weight\n",
            "layer1.1.bn3.weight\n",
            "layer1.1.bn3.bias\n",
            "layer1.1.bn3.running_mean\n",
            "layer1.1.bn3.running_var\n",
            "layer1.1.bn3.num_batches_tracked\n",
            "layer1.2.conv1.weight\n",
            "layer1.2.bn1.weight\n",
            "layer1.2.bn1.bias\n",
            "layer1.2.bn1.running_mean\n",
            "layer1.2.bn1.running_var\n",
            "layer1.2.bn1.num_batches_tracked\n",
            "layer1.2.conv2.weight\n",
            "layer1.2.bn2.weight\n",
            "layer1.2.bn2.bias\n",
            "layer1.2.bn2.running_mean\n",
            "layer1.2.bn2.running_var\n",
            "layer1.2.bn2.num_batches_tracked\n",
            "layer1.2.conv3.weight\n",
            "layer1.2.bn3.weight\n",
            "layer1.2.bn3.bias\n",
            "layer1.2.bn3.running_mean\n",
            "layer1.2.bn3.running_var\n",
            "layer1.2.bn3.num_batches_tracked\n",
            "layer2.0.conv1.weight\n",
            "layer2.0.bn1.weight\n",
            "layer2.0.bn1.bias\n",
            "layer2.0.bn1.running_mean\n",
            "layer2.0.bn1.running_var\n",
            "layer2.0.bn1.num_batches_tracked\n",
            "layer2.0.conv2.weight\n",
            "layer2.0.bn2.weight\n",
            "layer2.0.bn2.bias\n",
            "layer2.0.bn2.running_mean\n",
            "layer2.0.bn2.running_var\n",
            "layer2.0.bn2.num_batches_tracked\n",
            "layer2.0.conv3.weight\n",
            "layer2.0.bn3.weight\n",
            "layer2.0.bn3.bias\n",
            "layer2.0.bn3.running_mean\n",
            "layer2.0.bn3.running_var\n",
            "layer2.0.bn3.num_batches_tracked\n",
            "layer2.0.downsample.0.weight\n",
            "layer2.0.downsample.1.weight\n",
            "layer2.0.downsample.1.bias\n",
            "layer2.0.downsample.1.running_mean\n",
            "layer2.0.downsample.1.running_var\n",
            "layer2.0.downsample.1.num_batches_tracked\n",
            "layer2.1.conv1.weight\n",
            "layer2.1.bn1.weight\n",
            "layer2.1.bn1.bias\n",
            "layer2.1.bn1.running_mean\n",
            "layer2.1.bn1.running_var\n",
            "layer2.1.bn1.num_batches_tracked\n",
            "layer2.1.conv2.weight\n",
            "layer2.1.bn2.weight\n",
            "layer2.1.bn2.bias\n",
            "layer2.1.bn2.running_mean\n",
            "layer2.1.bn2.running_var\n",
            "layer2.1.bn2.num_batches_tracked\n",
            "layer2.1.conv3.weight\n",
            "layer2.1.bn3.weight\n",
            "layer2.1.bn3.bias\n",
            "layer2.1.bn3.running_mean\n",
            "layer2.1.bn3.running_var\n",
            "layer2.1.bn3.num_batches_tracked\n",
            "layer2.2.conv1.weight\n",
            "layer2.2.bn1.weight\n",
            "layer2.2.bn1.bias\n",
            "layer2.2.bn1.running_mean\n",
            "layer2.2.bn1.running_var\n",
            "layer2.2.bn1.num_batches_tracked\n",
            "layer2.2.conv2.weight\n",
            "layer2.2.bn2.weight\n",
            "layer2.2.bn2.bias\n",
            "layer2.2.bn2.running_mean\n",
            "layer2.2.bn2.running_var\n",
            "layer2.2.bn2.num_batches_tracked\n",
            "layer2.2.conv3.weight\n",
            "layer2.2.bn3.weight\n",
            "layer2.2.bn3.bias\n",
            "layer2.2.bn3.running_mean\n",
            "layer2.2.bn3.running_var\n",
            "layer2.2.bn3.num_batches_tracked\n",
            "layer2.3.conv1.weight\n",
            "layer2.3.bn1.weight\n",
            "layer2.3.bn1.bias\n",
            "layer2.3.bn1.running_mean\n",
            "layer2.3.bn1.running_var\n",
            "layer2.3.bn1.num_batches_tracked\n",
            "layer2.3.conv2.weight\n",
            "layer2.3.bn2.weight\n",
            "layer2.3.bn2.bias\n",
            "layer2.3.bn2.running_mean\n",
            "layer2.3.bn2.running_var\n",
            "layer2.3.bn2.num_batches_tracked\n",
            "layer2.3.conv3.weight\n",
            "layer2.3.bn3.weight\n",
            "layer2.3.bn3.bias\n",
            "layer2.3.bn3.running_mean\n",
            "layer2.3.bn3.running_var\n",
            "layer2.3.bn3.num_batches_tracked\n",
            "layer3.0.conv1.weight\n",
            "layer3.0.bn1.weight\n",
            "layer3.0.bn1.bias\n",
            "layer3.0.bn1.running_mean\n",
            "layer3.0.bn1.running_var\n",
            "layer3.0.bn1.num_batches_tracked\n",
            "layer3.0.conv2.weight\n",
            "layer3.0.bn2.weight\n",
            "layer3.0.bn2.bias\n",
            "layer3.0.bn2.running_mean\n",
            "layer3.0.bn2.running_var\n",
            "layer3.0.bn2.num_batches_tracked\n",
            "layer3.0.conv3.weight\n",
            "layer3.0.bn3.weight\n",
            "layer3.0.bn3.bias\n",
            "layer3.0.bn3.running_mean\n",
            "layer3.0.bn3.running_var\n",
            "layer3.0.bn3.num_batches_tracked\n",
            "layer3.0.downsample.0.weight\n",
            "layer3.0.downsample.1.weight\n",
            "layer3.0.downsample.1.bias\n",
            "layer3.0.downsample.1.running_mean\n",
            "layer3.0.downsample.1.running_var\n",
            "layer3.0.downsample.1.num_batches_tracked\n",
            "layer3.1.conv1.weight\n",
            "layer3.1.bn1.weight\n",
            "layer3.1.bn1.bias\n",
            "layer3.1.bn1.running_mean\n",
            "layer3.1.bn1.running_var\n",
            "layer3.1.bn1.num_batches_tracked\n",
            "layer3.1.conv2.weight\n",
            "layer3.1.bn2.weight\n",
            "layer3.1.bn2.bias\n",
            "layer3.1.bn2.running_mean\n",
            "layer3.1.bn2.running_var\n",
            "layer3.1.bn2.num_batches_tracked\n",
            "layer3.1.conv3.weight\n",
            "layer3.1.bn3.weight\n",
            "layer3.1.bn3.bias\n",
            "layer3.1.bn3.running_mean\n",
            "layer3.1.bn3.running_var\n",
            "layer3.1.bn3.num_batches_tracked\n",
            "layer3.2.conv1.weight\n",
            "layer3.2.bn1.weight\n",
            "layer3.2.bn1.bias\n",
            "layer3.2.bn1.running_mean\n",
            "layer3.2.bn1.running_var\n",
            "layer3.2.bn1.num_batches_tracked\n",
            "layer3.2.conv2.weight\n",
            "layer3.2.bn2.weight\n",
            "layer3.2.bn2.bias\n",
            "layer3.2.bn2.running_mean\n",
            "layer3.2.bn2.running_var\n",
            "layer3.2.bn2.num_batches_tracked\n",
            "layer3.2.conv3.weight\n",
            "layer3.2.bn3.weight\n",
            "layer3.2.bn3.bias\n",
            "layer3.2.bn3.running_mean\n",
            "layer3.2.bn3.running_var\n",
            "layer3.2.bn3.num_batches_tracked\n",
            "layer3.3.conv1.weight\n",
            "layer3.3.bn1.weight\n",
            "layer3.3.bn1.bias\n",
            "layer3.3.bn1.running_mean\n",
            "layer3.3.bn1.running_var\n",
            "layer3.3.bn1.num_batches_tracked\n",
            "layer3.3.conv2.weight\n",
            "layer3.3.bn2.weight\n",
            "layer3.3.bn2.bias\n",
            "layer3.3.bn2.running_mean\n",
            "layer3.3.bn2.running_var\n",
            "layer3.3.bn2.num_batches_tracked\n",
            "layer3.3.conv3.weight\n",
            "layer3.3.bn3.weight\n",
            "layer3.3.bn3.bias\n",
            "layer3.3.bn3.running_mean\n",
            "layer3.3.bn3.running_var\n",
            "layer3.3.bn3.num_batches_tracked\n",
            "layer3.4.conv1.weight\n",
            "layer3.4.bn1.weight\n",
            "layer3.4.bn1.bias\n",
            "layer3.4.bn1.running_mean\n",
            "layer3.4.bn1.running_var\n",
            "layer3.4.bn1.num_batches_tracked\n",
            "layer3.4.conv2.weight\n",
            "layer3.4.bn2.weight\n",
            "layer3.4.bn2.bias\n",
            "layer3.4.bn2.running_mean\n",
            "layer3.4.bn2.running_var\n",
            "layer3.4.bn2.num_batches_tracked\n",
            "layer3.4.conv3.weight\n",
            "layer3.4.bn3.weight\n",
            "layer3.4.bn3.bias\n",
            "layer3.4.bn3.running_mean\n",
            "layer3.4.bn3.running_var\n",
            "layer3.4.bn3.num_batches_tracked\n",
            "layer3.5.conv1.weight\n",
            "layer3.5.bn1.weight\n",
            "layer3.5.bn1.bias\n",
            "layer3.5.bn1.running_mean\n",
            "layer3.5.bn1.running_var\n",
            "layer3.5.bn1.num_batches_tracked\n",
            "layer3.5.conv2.weight\n",
            "layer3.5.bn2.weight\n",
            "layer3.5.bn2.bias\n",
            "layer3.5.bn2.running_mean\n",
            "layer3.5.bn2.running_var\n",
            "layer3.5.bn2.num_batches_tracked\n",
            "layer3.5.conv3.weight\n",
            "layer3.5.bn3.weight\n",
            "layer3.5.bn3.bias\n",
            "layer3.5.bn3.running_mean\n",
            "layer3.5.bn3.running_var\n",
            "layer3.5.bn3.num_batches_tracked\n",
            "layer4.0.conv1.weight\n",
            "layer4.0.bn1.weight\n",
            "layer4.0.bn1.bias\n",
            "layer4.0.bn1.running_mean\n",
            "layer4.0.bn1.running_var\n",
            "layer4.0.bn1.num_batches_tracked\n",
            "layer4.0.conv2.weight\n",
            "layer4.0.bn2.weight\n",
            "layer4.0.bn2.bias\n",
            "layer4.0.bn2.running_mean\n",
            "layer4.0.bn2.running_var\n",
            "layer4.0.bn2.num_batches_tracked\n",
            "layer4.0.conv3.weight\n",
            "layer4.0.bn3.weight\n",
            "layer4.0.bn3.bias\n",
            "layer4.0.bn3.running_mean\n",
            "layer4.0.bn3.running_var\n",
            "layer4.0.bn3.num_batches_tracked\n",
            "layer4.0.downsample.0.weight\n",
            "layer4.0.downsample.1.weight\n",
            "layer4.0.downsample.1.bias\n",
            "layer4.0.downsample.1.running_mean\n",
            "layer4.0.downsample.1.running_var\n",
            "layer4.0.downsample.1.num_batches_tracked\n",
            "layer4.1.conv1.weight\n",
            "layer4.1.bn1.weight\n",
            "layer4.1.bn1.bias\n",
            "layer4.1.bn1.running_mean\n",
            "layer4.1.bn1.running_var\n",
            "layer4.1.bn1.num_batches_tracked\n",
            "layer4.1.conv2.weight\n",
            "layer4.1.bn2.weight\n",
            "layer4.1.bn2.bias\n",
            "layer4.1.bn2.running_mean\n",
            "layer4.1.bn2.running_var\n",
            "layer4.1.bn2.num_batches_tracked\n",
            "layer4.1.conv3.weight\n",
            "layer4.1.bn3.weight\n",
            "layer4.1.bn3.bias\n",
            "layer4.1.bn3.running_mean\n",
            "layer4.1.bn3.running_var\n",
            "layer4.1.bn3.num_batches_tracked\n",
            "layer4.2.conv1.weight\n",
            "layer4.2.bn1.weight\n",
            "layer4.2.bn1.bias\n",
            "layer4.2.bn1.running_mean\n",
            "layer4.2.bn1.running_var\n",
            "layer4.2.bn1.num_batches_tracked\n",
            "layer4.2.conv2.weight\n",
            "layer4.2.bn2.weight\n",
            "layer4.2.bn2.bias\n",
            "layer4.2.bn2.running_mean\n",
            "layer4.2.bn2.running_var\n",
            "layer4.2.bn2.num_batches_tracked\n",
            "layer4.2.conv3.weight\n",
            "layer4.2.bn3.weight\n",
            "layer4.2.bn3.bias\n",
            "layer4.2.bn3.running_mean\n",
            "layer4.2.bn3.running_var\n",
            "layer4.2.bn3.num_batches_tracked\n",
            "fc.weight\n",
            "fc.bias\n"
          ]
        }
      ],
      "source": [
        "# Cek lapisan (layer) yang ada pada model weights_cover_model\n",
        "if isinstance(weights_cover_model, dict):\n",
        "    print(\"Daftar layer pada model (dict keys):\")\n",
        "    for layer_name in weights_cover_model.keys():\n",
        "        print(layer_name)\n",
        "elif hasattr(weights_cover_model, 'state_dict'):\n",
        "    print(\"Daftar layer pada model (state_dict keys):\")\n",
        "    for layer_name in weights_cover_model.state_dict().keys():\n",
        "        print(layer_name)\n",
        "else:\n",
        "    print(\"Tipe weights_cover_model tidak dikenali. Tipe:\", type(weights_cover_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8595e2b2",
      "metadata": {
        "id": "8595e2b2"
      },
      "source": [
        "#### *Fungsi Flatten dan Ekstraksi Bobot Cover*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "315877d4",
      "metadata": {
        "id": "315877d4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Asumsi fungsi load_model_weights sudah didefinisikan sebelumnya\n",
        "# def load_model_weights(file_path: str) -> dict: ...\n",
        "\n",
        "def get_flattened_cover_weights(cover_file_paths: list, target_layer: str = None) -> list:\n",
        "    \"\"\"\n",
        "    Memuat bobot dari daftar file model 'Cover', mengekstrak bobot float32 yang relevan,\n",
        "    dan meratakannya menjadi vektor tunggal.\n",
        "\n",
        "    Args:\n",
        "        cover_file_paths (list): Daftar path string ke file bobot model Cover (misalnya, .pth).\n",
        "        target_layer (str, optional): Nama lapisan bobot spesifik yang akan diekstrak\n",
        "                                    (misalnya, 'fc.weight'). Jika None, semua bobot float32 digabungkan.\n",
        "\n",
        "    Returns:\n",
        "        list: Daftar vektor NumPy 1D dari bobot model Cover yang diratakan.\n",
        "    \"\"\"\n",
        "    flattened_weights_list = []\n",
        "\n",
        "    # Menentukan target lapisan bobot mana yang akan diekstrak.\n",
        "    # Disarankan memilih semua bobot float32, bukan hanya satu lapisan,\n",
        "    # agar AE belajar representasi global bobot model.\n",
        "\n",
        "    # 1. Loop Melalui Setiap File Model Cover\n",
        "    for file_path in cover_file_paths:\n",
        "        try:\n",
        "            state_dict = load_model_weights(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Melewati {file_path}: Gagal memuat bobot. {e}\")\n",
        "            continue\n",
        "\n",
        "        current_model_weights = []\n",
        "\n",
        "        # 2. Iterasi Melalui Lapisan Bobot dalam state_dict\n",
        "        for name, tensor in state_dict.items():\n",
        "\n",
        "            # Hanya proses tensor float32\n",
        "            if tensor.dtype == torch.float32:\n",
        "\n",
        "                # Filter berdasarkan lapisan target jika ditentukan\n",
        "                if target_layer and name != target_layer:\n",
        "                    continue\n",
        "\n",
        "                # Pindahkan ke CPU dan konversi ke NumPy array, lalu ratakan (flatten)\n",
        "                weight_vector = tensor.cpu().numpy().flatten()\n",
        "                current_model_weights.append(weight_vector)\n",
        "\n",
        "        if not current_model_weights:\n",
        "            print(f\"Peringatan: Tidak ada bobot float32 yang ditemukan atau lapisan target '{target_layer}' tidak ada di {file_path}.\")\n",
        "            continue\n",
        "\n",
        "        # 3. Gabungkan Semua Vektor Bobot yang Diekstrak dari SATU MODEL\n",
        "        # Semua bobot model ResNet50/MobileNetV3 harus memiliki dimensi yang sama\n",
        "        # (sehingga NumPy.concatenate dapat bekerja)\n",
        "        try:\n",
        "            full_flattened_vector = np.concatenate(current_model_weights)\n",
        "            flattened_weights_list.append(full_flattened_vector)\n",
        "        except ValueError as e:\n",
        "            print(f\"Kesalahan dimensi pada {file_path}. Pastikan semua model memiliki arsitektur yang sama. {e}\")\n",
        "\n",
        "    # 4. Validasi Dimensi\n",
        "    if flattened_weights_list:\n",
        "        dim = flattened_weights_list[0].size\n",
        "        print(f\"\\nEkstraksi Selesai: Total {len(flattened_weights_list)} sampel bobot Cover.\")\n",
        "        print(f\"Dimensi setiap vektor (Input AE) adalah: {dim} fitur.\")\n",
        "\n",
        "    return flattened_weights_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9bfee933",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bfee933",
        "outputId": "2b5f6cb4-27f1-494a-bbe9-769c28732bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ekstraksi Selesai: Total 3 sampel bobot Cover.\n",
            "Dimensi setiap vektor (Input AE) adalah: 25610152 fitur.\n"
          ]
        }
      ],
      "source": [
        "# Asumsi Anda sudah mengumpulkan semua path file model Cover Anda\n",
        "cover_files = [\n",
        "    f\"{model_dir}/resnet50.pth\",\n",
        "    f\"{model_dir}/resnet50.pth\",\n",
        "    f\"{model_dir}/resnet50.pth\",\n",
        "    # ... Tambahkan sekitar 50-100 sampel model Cover yang berbeda\n",
        "]\n",
        "\n",
        "# 1. Dapatkan daftar vektor bobot yang diratakan\n",
        "cover_weights_list = get_flattened_cover_weights(cover_files)\n",
        "\n",
        "# # 2. Latih Autoencoder menggunakan daftar vektor bobot ini\n",
        "# if cover_weights_list:\n",
        "#     ae_model = train_autoencoder(cover_weights_list, epochs=100)\n",
        "\n",
        "    # Model ae_model ini sekarang siap digunakan di fungsi extract_loss_gradient!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f8a9f326",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8a9f326",
        "outputId": "6e0bdd53-0aa9-48e4-c525-f1887fd28235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([ 0.01333477,  0.0146636 , -0.015351  , ..., -0.01300753,\n",
            "        0.00777029,  0.00243688], dtype=float32), array([ 0.01333477,  0.0146636 , -0.015351  , ..., -0.01300753,\n",
            "        0.00777029,  0.00243688], dtype=float32), array([ 0.01333477,  0.0146636 , -0.015351  , ..., -0.01300753,\n",
            "        0.00777029,  0.00243688], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(cover_weights_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f1c35f60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "f1c35f60",
        "outputId": "30b756a3-e4de-4352-875e-17e7995e5a06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "[enforce fail at alloc_cpu.cpp:124] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 1311759770926208 bytes. Error code 12 (Cannot allocate memory)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-304658639.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mae_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_weights_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2448788182.py\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(cover_weights_list, epochs, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 2. Inisialisasi Model dan Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mae_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeightAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2232346331.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# Reduksi drastis untuk kompresi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         self.encoder = nn.Sequential(\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         self.weight = Parameter(\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:124] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 1311759770926208 bytes. Error code 12 (Cannot allocate memory)"
          ]
        }
      ],
      "source": [
        "ae_model = train_autoencoder(cover_weights_list, epochs=30)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "thesis-py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}