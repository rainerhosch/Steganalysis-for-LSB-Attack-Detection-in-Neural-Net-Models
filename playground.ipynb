{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2da6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ResNet Weight Steganalysis Research\n",
      "Initial memory: 63.51 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "print(\"Starting ResNet Weight Steganalysis Research\")\n",
    "print(f\"Initial memory: {psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d3a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loaded state_dict directly\n",
      "Total keys in state_dict: 320\n"
     ]
    }
   ],
   "source": [
    "# 1. Load model dan ekstrak bobot\n",
    "from WeightExtractor import WeightExtractor\n",
    "modelSelected = 'resnet50'\n",
    "print(\"Loading model...\")\n",
    "extractor = WeightExtractor(f'data/models/{modelSelected}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068457b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<WeightExtractor.WeightExtractor object at 0x0000022F6DA72800>\n"
     ]
    }
   ],
   "source": [
    "print(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8211b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer statistics (first 10 layers):\n",
      "conv1.weight: shapetorch.Size([64, 3, 7, 7]), elements: 9408\n",
      "bn1.weight: shapetorch.Size([64]), elements: 64\n",
      "bn1.bias: shapetorch.Size([64]), elements: 64\n",
      "bn1.running_mean: shapetorch.Size([64]), elements: 64\n",
      "bn1.running_var: shapetorch.Size([64]), elements: 64\n",
      "bn1.num_batches_tracked: shapetorch.Size([]), elements: 1\n",
      "layer1.0.conv1.weight: shapetorch.Size([64, 64, 1, 1]), elements: 4096\n",
      "layer1.0.bn1.weight: shapetorch.Size([64]), elements: 64\n",
      "layer1.0.bn1.bias: shapetorch.Size([64]), elements: 64\n",
      "layer1.0.bn1.running_mean: shapetorch.Size([64]), elements: 64\n"
     ]
    }
   ],
   "source": [
    "# Lihat statistik layer\n",
    "stats = extractor.get_layer_statistics()\n",
    "print(\"\\nLayer statistics (first 10 layers):\")\n",
    "for i, (name, stat) in enumerate(list(stats.items())[:10]):\n",
    "    print(f\"{name}: shape{stat['shape']}, elements: {stat['numel']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31eb6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extracting all convolutional weights ===\n",
      "Extracting: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Extracting: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 1, 1])\n",
      "Extracting: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Extracting: layer1.0.conv3.weight, Shape: torch.Size([256, 64, 1, 1])\n",
      "Extracting: layer1.0.downsample.0.weight, Shape: torch.Size([256, 64, 1, 1])\n",
      "Memory usage: 305.85 MB\n",
      "Extracting: layer1.1.conv1.weight, Shape: torch.Size([64, 256, 1, 1])\n",
      "Extracting: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Extracting: layer1.1.conv3.weight, Shape: torch.Size([256, 64, 1, 1])\n",
      "Extracting: layer1.2.conv1.weight, Shape: torch.Size([64, 256, 1, 1])\n",
      "Extracting: layer1.2.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Memory usage: 306.32 MB\n",
      "Extracting: layer1.2.conv3.weight, Shape: torch.Size([256, 64, 1, 1])\n",
      "Extracting: layer2.0.conv1.weight, Shape: torch.Size([128, 256, 1, 1])\n",
      "Extracting: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Extracting: layer2.0.conv3.weight, Shape: torch.Size([512, 128, 1, 1])\n",
      "Extracting: layer2.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1])\n",
      "Memory usage: 307.83 MB\n",
      "Extracting: layer2.1.conv1.weight, Shape: torch.Size([128, 512, 1, 1])\n",
      "Extracting: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Extracting: layer2.1.conv3.weight, Shape: torch.Size([512, 128, 1, 1])\n",
      "Extracting: layer2.2.conv1.weight, Shape: torch.Size([128, 512, 1, 1])\n",
      "Extracting: layer2.2.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Memory usage: 309.70 MB\n",
      "Extracting: layer2.2.conv3.weight, Shape: torch.Size([512, 128, 1, 1])\n",
      "Extracting: layer2.3.conv1.weight, Shape: torch.Size([128, 512, 1, 1])\n",
      "Extracting: layer2.3.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Extracting: layer2.3.conv3.weight, Shape: torch.Size([512, 128, 1, 1])\n",
      "Extracting: layer3.0.conv1.weight, Shape: torch.Size([256, 512, 1, 1])\n",
      "Memory usage: 311.52 MB\n",
      "Extracting: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.0.conv3.weight, Shape: torch.Size([1024, 256, 1, 1])\n",
      "Extracting: layer3.0.downsample.0.weight, Shape: torch.Size([1024, 512, 1, 1])\n",
      "Extracting: layer3.1.conv1.weight, Shape: torch.Size([256, 1024, 1, 1])\n",
      "Extracting: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Memory usage: 320.04 MB\n",
      "Extracting: layer3.1.conv3.weight, Shape: torch.Size([1024, 256, 1, 1])\n",
      "Extracting: layer3.2.conv1.weight, Shape: torch.Size([256, 1024, 1, 1])\n",
      "Extracting: layer3.2.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.2.conv3.weight, Shape: torch.Size([1024, 256, 1, 1])\n",
      "Extracting: layer3.3.conv1.weight, Shape: torch.Size([256, 1024, 1, 1])\n",
      "Memory usage: 326.30 MB\n",
      "Extracting: layer3.3.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.3.conv3.weight, Shape: torch.Size([1024, 256, 1, 1])\n",
      "Extracting: layer3.4.conv1.weight, Shape: torch.Size([256, 1024, 1, 1])\n",
      "Extracting: layer3.4.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.4.conv3.weight, Shape: torch.Size([1024, 256, 1, 1])\n",
      "Memory usage: 333.82 MB\n",
      "Extracting: layer3.5.conv1.weight, Shape: torch.Size([256, 1024, 1, 1])\n",
      "Extracting: layer3.5.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.5.conv3.weight, Shape: torch.Size([1024, 256, 1, 1])\n",
      "Extracting: layer4.0.conv1.weight, Shape: torch.Size([512, 1024, 1, 1])\n",
      "Extracting: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Memory usage: 349.09 MB\n",
      "Extracting: layer4.0.conv3.weight, Shape: torch.Size([2048, 512, 1, 1])\n",
      "Extracting: layer4.0.downsample.0.weight, Shape: torch.Size([2048, 1024, 1, 1])\n",
      "Extracting: layer4.1.conv1.weight, Shape: torch.Size([512, 2048, 1, 1])\n",
      "Extracting: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Extracting: layer4.1.conv3.weight, Shape: torch.Size([2048, 512, 1, 1])\n",
      "Memory usage: 378.12 MB\n",
      "Extracting: layer4.2.conv1.weight, Shape: torch.Size([512, 2048, 1, 1])\n",
      "Extracting: layer4.2.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Extracting: layer4.2.conv3.weight, Shape: torch.Size([2048, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Opsi 1: Ekstrak semua bobot convolutional\n",
    "print(\"\\n=== Extracting all convolutional weights ===\")\n",
    "conv_weights, layer_names = extractor.extract_conv_weights_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957e963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not conv_weights:\n",
    "    print(\"No convolutional weights found! Trying alternative extraction...\")\n",
    "    # Fallback: ekstrak semua weights yang ada\n",
    "    conv_weights = []\n",
    "    for name, param in extractor.state_dict.items():\n",
    "        if 'weight' in name and len(param.shape) >= 2:  # Filter kemungkinan conv weights\n",
    "            weight_vec = param.cpu().numpy().flatten()\n",
    "            conv_weights.append(weight_vec)\n",
    "            print(f\"Fallback extraction: {name}, {len(weight_vec)} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "348f5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 53 convolutional layers weight\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nExtracted {len(conv_weights)} convolutional layers weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03653eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preparing training data ===\n",
      "Processing weight data with max_samples: 5000\n",
      "Weight array 0: 9408 weights -> 294 sequences\n",
      "Weight array 1: 4096 weights -> 128 sequences\n",
      "Weight array 2: 36864 weights -> 1152 sequences\n",
      "Dataset created: 1574 sequences of length 32\n"
     ]
    }
   ],
   "source": [
    "# 3. Persiapkan data training dengan parameter yang benar\n",
    "print(\"\\n=== Preparing training data ===\")\n",
    "\n",
    "# Gunakan hanya 2-3 layer pertama untuk menghemat memory\n",
    "training_weights = conv_weights[:3] if len(conv_weights) >= 3 else conv_weights\n",
    "        \n",
    "# Buat dataset dengan parameter yang sesuai\n",
    "from Autoencoder import WeightDataset\n",
    "dataset = WeightDataset(\n",
    "    weight_data=training_weights,\n",
    "    seq_length=32,  # Sequence length lebih kecil\n",
    "    max_samples=5000  # Batasi jumlah samples coba 2000\n",
    ")\n",
    "\n",
    "if len(dataset) == 0:\n",
    "    # Fallback: coba dengan seq_length yang lebih kecil\n",
    "    print(\"No data with seq_length=128, trying with smaller seq_length...\")\n",
    "    dataset = WeightDataset(\n",
    "        weight_data=training_weights,\n",
    "        seq_length=64,  # Lebih kecil\n",
    "        max_samples=2000\n",
    "    )\n",
    "if len(dataset) == 0:\n",
    "    raise ValueError(\"No training data available even with smaller seq_length!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2353384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1574\n",
      "Batch size: 4\n",
      "Memory before training: 396.27 MB\n"
     ]
    }
   ],
   "source": [
    "# DataLoader dengan batch size sangat kecil\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "print(f\"Training samples: {len(dataset)}\")\n",
    "print(f\"Batch size: 4\")\n",
    "print(f\"Memory before training: {psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe02ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 32\n"
     ]
    }
   ],
   "source": [
    "# 4. Inisialisasi model kecil\n",
    "input_dim = dataset[0][0].shape[0]\n",
    "print(f\"Input dimension: {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "256b8d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 8,936\n"
     ]
    }
   ],
   "source": [
    "from Autoencoder import Autoencoder\n",
    "autoencoder = Autoencoder(input_dim=input_dim, encoding_dim=8)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in autoencoder.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700527b",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a608270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Training ===\n",
      "Epoch 0, Batch 0, Loss: 0.926044, Memory: 453.43 MB\n",
      "Epoch 0, Batch 10, Loss: 0.991969, Memory: 453.51 MB\n",
      "Epoch 0, Batch 20, Loss: 0.945334, Memory: 453.50 MB\n",
      "Epoch 0, Batch 30, Loss: 0.962521, Memory: 453.50 MB\n",
      "Epoch 0, Batch 40, Loss: 0.934465, Memory: 453.50 MB\n",
      "Epoch 0 completed. Average Loss: 0.963880\n",
      "Epoch 1, Batch 0, Loss: 0.927964, Memory: 453.71 MB\n",
      "Epoch 1, Batch 10, Loss: 0.915919, Memory: 453.73 MB\n",
      "Epoch 1, Batch 20, Loss: 0.836275, Memory: 453.64 MB\n",
      "Epoch 1, Batch 30, Loss: 0.892575, Memory: 453.64 MB\n",
      "Epoch 1, Batch 40, Loss: 0.783985, Memory: 453.64 MB\n",
      "Epoch 1 completed. Average Loss: 0.861073\n",
      "Epoch 2, Batch 0, Loss: 0.765603, Memory: 453.73 MB\n",
      "Epoch 2, Batch 10, Loss: 0.767092, Memory: 453.73 MB\n",
      "Epoch 2, Batch 20, Loss: 0.740791, Memory: 453.65 MB\n",
      "Epoch 2, Batch 30, Loss: 0.769932, Memory: 453.65 MB\n",
      "Epoch 2, Batch 40, Loss: 0.750337, Memory: 453.65 MB\n",
      "Epoch 2 completed. Average Loss: 0.776275\n",
      "Epoch 3, Batch 0, Loss: 0.815750, Memory: 453.73 MB\n",
      "Epoch 3, Batch 10, Loss: 0.784890, Memory: 453.73 MB\n",
      "Epoch 3, Batch 20, Loss: 0.735987, Memory: 453.65 MB\n",
      "Epoch 3, Batch 30, Loss: 0.756511, Memory: 453.65 MB\n",
      "Epoch 3, Batch 40, Loss: 0.744278, Memory: 453.65 MB\n",
      "Epoch 3 completed. Average Loss: 0.751423\n",
      "Epoch 4, Batch 0, Loss: 0.777482, Memory: 453.73 MB\n",
      "Epoch 4, Batch 10, Loss: 0.725960, Memory: 453.73 MB\n",
      "Epoch 4, Batch 20, Loss: 0.742043, Memory: 453.65 MB\n",
      "Epoch 4, Batch 30, Loss: 0.775159, Memory: 453.65 MB\n",
      "Epoch 4, Batch 40, Loss: 0.686316, Memory: 453.65 MB\n",
      "Epoch 4 completed. Average Loss: 0.729918\n",
      "Epoch 5, Batch 0, Loss: 0.740601, Memory: 453.73 MB\n",
      "Epoch 5, Batch 10, Loss: 0.741681, Memory: 453.73 MB\n",
      "Epoch 5, Batch 20, Loss: 0.699097, Memory: 453.65 MB\n",
      "Epoch 5, Batch 30, Loss: 0.712793, Memory: 453.65 MB\n",
      "Epoch 5, Batch 40, Loss: 0.726561, Memory: 453.65 MB\n",
      "Epoch 5 completed. Average Loss: 0.705957\n",
      "Epoch 6, Batch 0, Loss: 0.679694, Memory: 453.73 MB\n",
      "Epoch 6, Batch 10, Loss: 0.715503, Memory: 453.73 MB\n",
      "Epoch 6, Batch 20, Loss: 0.679476, Memory: 453.65 MB\n",
      "Epoch 6, Batch 30, Loss: 0.666476, Memory: 453.65 MB\n",
      "Epoch 6, Batch 40, Loss: 0.745721, Memory: 453.65 MB\n",
      "Epoch 6 completed. Average Loss: 0.682451\n",
      "Epoch 7, Batch 0, Loss: 0.672027, Memory: 453.73 MB\n",
      "Epoch 7, Batch 10, Loss: 0.641704, Memory: 453.73 MB\n",
      "Epoch 7, Batch 20, Loss: 0.608920, Memory: 453.65 MB\n",
      "Epoch 7, Batch 30, Loss: 0.661603, Memory: 453.65 MB\n",
      "Epoch 7, Batch 40, Loss: 0.735471, Memory: 453.65 MB\n",
      "Epoch 7 completed. Average Loss: 0.673919\n",
      "Epoch 8, Batch 0, Loss: 0.663205, Memory: 453.74 MB\n",
      "Epoch 8, Batch 10, Loss: 0.653096, Memory: 453.74 MB\n",
      "Epoch 8, Batch 20, Loss: 0.652095, Memory: 453.66 MB\n",
      "Epoch 8, Batch 30, Loss: 0.668929, Memory: 453.66 MB\n",
      "Epoch 8, Batch 40, Loss: 0.655642, Memory: 453.66 MB\n",
      "Epoch 8 completed. Average Loss: 0.663970\n",
      "Epoch 9, Batch 0, Loss: 0.677583, Memory: 453.74 MB\n",
      "Epoch 9, Batch 10, Loss: 0.706746, Memory: 453.74 MB\n",
      "Epoch 9, Batch 20, Loss: 0.717076, Memory: 453.66 MB\n",
      "Epoch 9, Batch 30, Loss: 0.679761, Memory: 453.66 MB\n",
      "Epoch 9, Batch 40, Loss: 0.627456, Memory: 453.66 MB\n",
      "Epoch 9 completed. Average Loss: 0.649312\n",
      "Epoch 10, Batch 0, Loss: 0.665448, Memory: 453.74 MB\n",
      "Epoch 10, Batch 10, Loss: 0.658977, Memory: 453.74 MB\n",
      "Epoch 10, Batch 20, Loss: 0.631257, Memory: 453.66 MB\n",
      "Epoch 10, Batch 30, Loss: 0.583346, Memory: 453.66 MB\n",
      "Epoch 10, Batch 40, Loss: 0.670979, Memory: 453.66 MB\n",
      "Epoch 10 completed. Average Loss: 0.634480\n",
      "Epoch 11, Batch 0, Loss: 0.677655, Memory: 453.75 MB\n",
      "Epoch 11, Batch 10, Loss: 0.626341, Memory: 453.75 MB\n",
      "Epoch 11, Batch 20, Loss: 0.644728, Memory: 453.66 MB\n",
      "Epoch 11, Batch 30, Loss: 0.634085, Memory: 453.66 MB\n",
      "Epoch 11, Batch 40, Loss: 0.578927, Memory: 453.66 MB\n",
      "Epoch 11 completed. Average Loss: 0.621678\n",
      "Epoch 12, Batch 0, Loss: 0.607229, Memory: 453.75 MB\n",
      "Epoch 12, Batch 10, Loss: 0.635475, Memory: 453.75 MB\n",
      "Epoch 12, Batch 20, Loss: 0.651023, Memory: 453.66 MB\n",
      "Epoch 12, Batch 30, Loss: 0.631143, Memory: 453.66 MB\n",
      "Epoch 12, Batch 40, Loss: 0.694249, Memory: 453.66 MB\n",
      "Epoch 12 completed. Average Loss: 0.611579\n",
      "Epoch 13, Batch 0, Loss: 0.626817, Memory: 453.75 MB\n",
      "Epoch 13, Batch 10, Loss: 0.606254, Memory: 453.75 MB\n",
      "Epoch 13, Batch 20, Loss: 0.556601, Memory: 453.66 MB\n",
      "Epoch 13, Batch 30, Loss: 0.660653, Memory: 453.66 MB\n",
      "Epoch 13, Batch 40, Loss: 0.592247, Memory: 453.66 MB\n",
      "Epoch 13 completed. Average Loss: 0.608635\n",
      "Epoch 14, Batch 0, Loss: 0.633028, Memory: 453.75 MB\n",
      "Epoch 14, Batch 10, Loss: 0.604997, Memory: 453.75 MB\n",
      "Epoch 14, Batch 20, Loss: 0.550751, Memory: 453.67 MB\n",
      "Epoch 14, Batch 30, Loss: 0.582645, Memory: 453.67 MB\n",
      "Epoch 14, Batch 40, Loss: 0.541580, Memory: 453.67 MB\n",
      "Epoch 14 completed. Average Loss: 0.603493\n",
      "Epoch 15, Batch 0, Loss: 0.567674, Memory: 453.75 MB\n",
      "Epoch 15, Batch 10, Loss: 0.647857, Memory: 453.75 MB\n",
      "Epoch 15, Batch 20, Loss: 0.610995, Memory: 453.67 MB\n",
      "Epoch 15, Batch 30, Loss: 0.642160, Memory: 453.67 MB\n",
      "Epoch 15, Batch 40, Loss: 0.677567, Memory: 453.67 MB\n",
      "Epoch 15 completed. Average Loss: 0.603176\n",
      "Epoch 16, Batch 0, Loss: 0.601661, Memory: 453.75 MB\n",
      "Epoch 16, Batch 10, Loss: 0.584077, Memory: 453.75 MB\n",
      "Epoch 16, Batch 20, Loss: 0.608168, Memory: 453.67 MB\n",
      "Epoch 16, Batch 30, Loss: 0.625366, Memory: 453.67 MB\n",
      "Epoch 16, Batch 40, Loss: 0.616013, Memory: 453.67 MB\n",
      "Epoch 16 completed. Average Loss: 0.596326\n",
      "Epoch 17, Batch 0, Loss: 0.586092, Memory: 453.75 MB\n",
      "Epoch 17, Batch 10, Loss: 0.596927, Memory: 453.75 MB\n",
      "Epoch 17, Batch 20, Loss: 0.637685, Memory: 453.67 MB\n",
      "Epoch 17, Batch 30, Loss: 0.614976, Memory: 453.67 MB\n",
      "Epoch 17, Batch 40, Loss: 0.621768, Memory: 453.67 MB\n",
      "Epoch 17 completed. Average Loss: 0.594386\n",
      "Epoch 18, Batch 0, Loss: 0.578329, Memory: 453.76 MB\n",
      "Epoch 18, Batch 10, Loss: 0.601743, Memory: 453.76 MB\n",
      "Epoch 18, Batch 20, Loss: 0.572915, Memory: 453.68 MB\n",
      "Epoch 18, Batch 30, Loss: 0.552422, Memory: 453.68 MB\n",
      "Epoch 18, Batch 40, Loss: 0.626414, Memory: 453.68 MB\n",
      "Epoch 18 completed. Average Loss: 0.594601\n",
      "Epoch 19, Batch 0, Loss: 0.595677, Memory: 453.76 MB\n",
      "Epoch 19, Batch 10, Loss: 0.587967, Memory: 453.76 MB\n",
      "Epoch 19, Batch 20, Loss: 0.655163, Memory: 453.68 MB\n",
      "Epoch 19, Batch 30, Loss: 0.636883, Memory: 453.68 MB\n",
      "Epoch 19, Batch 40, Loss: 0.524625, Memory: 453.68 MB\n",
      "Epoch 19 completed. Average Loss: 0.593404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Starting Training ===\")\n",
    "from Training import train_with_progress, train_with_memory_monitoring, simple_train\n",
    "# Pilih salah satu metode training:\n",
    "trained_model = train_with_memory_monitoring(autoencoder, dataloader, epochs=20, modelSelected=modelSelected)\n",
    "# trained_model = simple_train(autoencoder, dataloader, epochs=2)\n",
    "# trained_model = train_with_progress(autoencoder, dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf463af",
   "metadata": {},
   "source": [
    "### # Simpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03679650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.save(trained_model.state_dict(), f'data/models/{modelSelected}_autoencoder_final.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f8215",
   "metadata": {},
   "source": [
    "### # Test reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d79b684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Reconstruction ===\n",
      "Test reconstruction loss: 0.391117\n",
      "Research completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Testing Reconstruction ===\")\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_sample, _ = dataset[0]\n",
    "    test_sample = test_sample.unsqueeze(0)\n",
    "    encoded, decoded = trained_model(test_sample)\n",
    "    test_loss = nn.MSELoss()(decoded, test_sample)\n",
    "    print(f\"Test reconstruction loss: {test_loss.item():.6f}\")\n",
    "        \n",
    "print(\"Research completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
