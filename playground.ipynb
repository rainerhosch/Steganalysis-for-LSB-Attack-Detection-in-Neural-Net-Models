{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2da6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ResNet Weight Steganalysis Research\n",
      "Initial memory: 63.25 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "print(\"Starting ResNet Weight Steganalysis Research\")\n",
    "print(f\"Initial memory: {psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d3a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loaded state_dict directly\n",
      "Total keys in state_dict: 122\n"
     ]
    }
   ],
   "source": [
    "# 1. Load model dan ekstrak bobot\n",
    "from ResNetWeightExtractorX import ResNetWeightExtractorX\n",
    "modelSelected = 'resnet18'\n",
    "print(\"Loading model...\")\n",
    "extractorX = ResNetWeightExtractorX(f'../data/models/{modelSelected}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068457b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ResNetWeightExtractorX.ResNetWeightExtractorX object at 0x000001572B8834F0>\n"
     ]
    }
   ],
   "source": [
    "print(extractorX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8211b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer statistics (first 10 layers):\n",
      "conv1.weight: shapetorch.Size([64, 3, 7, 7]), elements: 9408\n",
      "bn1.weight: shapetorch.Size([64]), elements: 64\n",
      "bn1.bias: shapetorch.Size([64]), elements: 64\n",
      "bn1.running_mean: shapetorch.Size([64]), elements: 64\n",
      "bn1.running_var: shapetorch.Size([64]), elements: 64\n",
      "bn1.num_batches_tracked: shapetorch.Size([]), elements: 1\n",
      "layer1.0.conv1.weight: shapetorch.Size([64, 64, 3, 3]), elements: 36864\n",
      "layer1.0.bn1.weight: shapetorch.Size([64]), elements: 64\n",
      "layer1.0.bn1.bias: shapetorch.Size([64]), elements: 64\n",
      "layer1.0.bn1.running_mean: shapetorch.Size([64]), elements: 64\n"
     ]
    }
   ],
   "source": [
    "# Lihat statistik layer\n",
    "stats = extractorX.get_layer_statistics()\n",
    "print(\"\\nLayer statistics (first 10 layers):\")\n",
    "for i, (name, stat) in enumerate(list(stats.items())[:10]):\n",
    "    print(f\"{name}: shape{stat['shape']}, elements: {stat['numel']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31eb6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extracting all convolutional weights ===\n",
      "Extracting: conv1.weight, Shape: torch.Size([64, 3, 7, 7])\n",
      "Extracting: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Extracting: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Extracting: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Extracting: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3])\n",
      "Memory usage: 251.16 MB\n",
      "Extracting: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3])\n",
      "Extracting: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Extracting: layer2.0.downsample.0.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Extracting: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Extracting: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3])\n",
      "Memory usage: 253.17 MB\n",
      "Extracting: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Extracting: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.0.downsample.0.weight, Shape: torch.Size([256, 128, 1, 1])\n",
      "Extracting: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Extracting: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Memory usage: 261.19 MB\n",
      "Extracting: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3])\n",
      "Extracting: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Extracting: layer4.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1])\n",
      "Extracting: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Extracting: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3])\n",
      "Memory usage: 293.20 MB\n"
     ]
    }
   ],
   "source": [
    "# Opsi 1: Ekstrak semua bobot convolutional\n",
    "print(\"\\n=== Extracting all convolutional weights ===\")\n",
    "conv_weights, layer_names = extractorX.extract_conv_weights_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957e963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not conv_weights:\n",
    "    print(\"No convolutional weights found! Trying alternative extraction...\")\n",
    "    # Fallback: ekstrak semua weights yang ada\n",
    "    conv_weights = []\n",
    "    for name, param in extractorX.state_dict.items():\n",
    "        if 'weight' in name and len(param.shape) >= 2:  # Filter kemungkinan conv weights\n",
    "            weight_vec = param.cpu().numpy().flatten()\n",
    "            conv_weights.append(weight_vec)\n",
    "            print(f\"Fallback extraction: {name}, {len(weight_vec)} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c87bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully extracted 20 weight arrays\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSuccessfully extracted {len(conv_weights)} weight arrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348f5be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 20 convolutional layers\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nExtracted {len(conv_weights)} convolutional layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03653eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preparing training data ===\n",
      "Processing weight data with max_samples: 2000\n",
      "Weight array 0: 9408 weights -> 73 sequences\n",
      "Weight array 1: 36864 weights -> 288 sequences\n",
      "Weight array 2: 36864 weights -> 288 sequences\n",
      "Dataset created: 649 sequences of length 128\n"
     ]
    }
   ],
   "source": [
    "# 3. Persiapkan data training dengan parameter yang benar\n",
    "print(\"\\n=== Preparing training data ===\")\n",
    "\n",
    "# Gunakan hanya 2-3 layer pertama untuk menghemat memory\n",
    "training_weights = conv_weights[:3] if len(conv_weights) >= 3 else conv_weights\n",
    "        \n",
    "# Buat dataset dengan parameter yang sesuai\n",
    "from SteganalysisAutoencoder import WeightDataset\n",
    "dataset = WeightDataset(\n",
    "    weight_data=training_weights,\n",
    "    seq_length=128,  # Sequence length lebih kecil\n",
    "    max_samples=2000  # Batasi jumlah samples\n",
    ")\n",
    "\n",
    "if len(dataset) == 0:\n",
    "    # Fallback: coba dengan seq_length yang lebih kecil\n",
    "    print(\"No data with seq_length=128, trying with smaller seq_length...\")\n",
    "    dataset = WeightDataset(\n",
    "        weight_data=training_weights,\n",
    "        seq_length=64,  # Lebih kecil\n",
    "        max_samples=2000\n",
    "    )\n",
    "if len(dataset) == 0:\n",
    "    raise ValueError(\"No training data available even with smaller seq_length!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2353384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 649\n",
      "Batch size: 4\n",
      "Memory before training: 294.26 MB\n"
     ]
    }
   ],
   "source": [
    "# DataLoader dengan batch size sangat kecil\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "print(f\"Training samples: {len(dataset)}\")\n",
    "print(f\"Batch size: 4\")\n",
    "print(f\"Memory before training: {psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe02ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 128\n"
     ]
    }
   ],
   "source": [
    "# 4. Inisialisasi model kecil\n",
    "input_dim = dataset[0][0].shape[0]\n",
    "print(f\"Input dimension: {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256b8d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 21,320\n"
     ]
    }
   ],
   "source": [
    "from SteganalysisAutoencoder import SteganalysisAutoencoder\n",
    "autoencoder = SteganalysisAutoencoder(input_dim=input_dim, encoding_dim=8)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in autoencoder.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700527b",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Training ===\n",
      "Epoch 0, Batch 0, Loss: 0.739480, Memory: 352.35 MB\n",
      "Epoch 0, Batch 10, Loss: 0.815997, Memory: 352.37 MB\n",
      "Epoch 0, Batch 20, Loss: 0.756442, Memory: 352.37 MB\n",
      "Epoch 0, Batch 30, Loss: 0.800024, Memory: 352.40 MB\n",
      "Epoch 0, Batch 40, Loss: 0.733418, Memory: 352.36 MB\n",
      "Epoch 0, Batch 50, Loss: 0.797735, Memory: 352.36 MB\n",
      "Epoch 0, Batch 60, Loss: 0.870083, Memory: 352.36 MB\n",
      "Epoch 0, Batch 70, Loss: 0.781786, Memory: 352.36 MB\n",
      "Epoch 0, Batch 80, Loss: 0.775986, Memory: 352.36 MB\n",
      "Epoch 0, Batch 90, Loss: 0.815807, Memory: 352.36 MB\n",
      "Epoch 0, Batch 100, Loss: 0.704798, Memory: 352.36 MB\n",
      "Epoch 0, Batch 110, Loss: 0.778827, Memory: 352.36 MB\n",
      "Epoch 0, Batch 120, Loss: 0.645098, Memory: 352.36 MB\n",
      "Epoch 0, Batch 130, Loss: 0.805736, Memory: 352.36 MB\n",
      "Epoch 0, Batch 140, Loss: 0.627133, Memory: 352.36 MB\n",
      "Epoch 0, Batch 150, Loss: 0.799716, Memory: 352.36 MB\n",
      "Epoch 0, Batch 160, Loss: 0.816288, Memory: 352.36 MB\n",
      "Epoch 0 completed. Average Loss: 0.793477\n",
      "Epoch 1, Batch 0, Loss: 0.692034, Memory: 352.38 MB\n",
      "Epoch 1, Batch 10, Loss: 0.834162, Memory: 352.38 MB\n",
      "Epoch 1, Batch 20, Loss: 0.724794, Memory: 352.38 MB\n",
      "Epoch 1, Batch 30, Loss: 0.759199, Memory: 352.38 MB\n",
      "Epoch 1, Batch 40, Loss: 0.848628, Memory: 352.37 MB\n",
      "Epoch 1, Batch 50, Loss: 0.840664, Memory: 352.37 MB\n",
      "Epoch 1, Batch 60, Loss: 0.747748, Memory: 352.37 MB\n",
      "Epoch 1, Batch 70, Loss: 0.894639, Memory: 352.37 MB\n",
      "Epoch 1, Batch 80, Loss: 0.807371, Memory: 352.37 MB\n",
      "Epoch 1, Batch 90, Loss: 0.814083, Memory: 352.37 MB\n",
      "Epoch 1, Batch 100, Loss: 0.748279, Memory: 352.37 MB\n",
      "Epoch 1, Batch 110, Loss: 0.735708, Memory: 352.37 MB\n",
      "Epoch 1, Batch 120, Loss: 0.841708, Memory: 352.37 MB\n",
      "Epoch 1, Batch 130, Loss: 0.776950, Memory: 352.37 MB\n",
      "Epoch 1, Batch 140, Loss: 0.709437, Memory: 352.37 MB\n",
      "Epoch 1, Batch 150, Loss: 0.766704, Memory: 352.37 MB\n",
      "Epoch 1, Batch 160, Loss: 0.737438, Memory: 352.37 MB\n",
      "Epoch 1 completed. Average Loss: 0.788917\n",
      "Epoch 2, Batch 0, Loss: 0.787889, Memory: 352.38 MB\n",
      "Epoch 2, Batch 10, Loss: 0.655086, Memory: 352.38 MB\n",
      "Epoch 2, Batch 20, Loss: 0.795885, Memory: 352.38 MB\n",
      "Epoch 2, Batch 30, Loss: 0.732555, Memory: 352.38 MB\n",
      "Epoch 2, Batch 40, Loss: 0.761124, Memory: 352.37 MB\n",
      "Epoch 2, Batch 50, Loss: 0.868105, Memory: 352.37 MB\n",
      "Epoch 2, Batch 60, Loss: 0.886916, Memory: 352.37 MB\n",
      "Epoch 2, Batch 70, Loss: 0.697051, Memory: 352.37 MB\n",
      "Epoch 2, Batch 80, Loss: 0.871862, Memory: 352.37 MB\n",
      "Epoch 2, Batch 90, Loss: 0.774555, Memory: 352.37 MB\n",
      "Epoch 2, Batch 100, Loss: 0.734467, Memory: 352.37 MB\n",
      "Epoch 2, Batch 110, Loss: 0.745690, Memory: 352.37 MB\n",
      "Epoch 2, Batch 120, Loss: 0.847454, Memory: 352.37 MB\n",
      "Epoch 2, Batch 130, Loss: 0.699337, Memory: 352.37 MB\n",
      "Epoch 2, Batch 140, Loss: 0.839186, Memory: 352.37 MB\n",
      "Epoch 2, Batch 150, Loss: 0.698253, Memory: 352.37 MB\n",
      "Epoch 2, Batch 160, Loss: 0.787575, Memory: 352.37 MB\n",
      "Epoch 2 completed. Average Loss: 0.788972\n",
      "Epoch 3, Batch 0, Loss: 0.704386, Memory: 352.38 MB\n",
      "Epoch 3, Batch 10, Loss: 0.791955, Memory: 352.38 MB\n",
      "Epoch 3, Batch 20, Loss: 0.667943, Memory: 352.38 MB\n",
      "Epoch 3, Batch 30, Loss: 0.852533, Memory: 352.38 MB\n",
      "Epoch 3, Batch 40, Loss: 0.841914, Memory: 352.37 MB\n",
      "Epoch 3, Batch 50, Loss: 0.919077, Memory: 352.37 MB\n",
      "Epoch 3, Batch 60, Loss: 0.854388, Memory: 352.37 MB\n",
      "Epoch 3, Batch 70, Loss: 0.715404, Memory: 352.37 MB\n",
      "Epoch 3, Batch 80, Loss: 0.728473, Memory: 352.37 MB\n",
      "Epoch 3, Batch 90, Loss: 0.830885, Memory: 352.37 MB\n",
      "Epoch 3, Batch 100, Loss: 0.816826, Memory: 352.37 MB\n",
      "Epoch 3, Batch 110, Loss: 0.715602, Memory: 352.37 MB\n",
      "Epoch 3, Batch 120, Loss: 0.795131, Memory: 352.37 MB\n",
      "Epoch 3, Batch 130, Loss: 0.782688, Memory: 352.37 MB\n",
      "Epoch 3, Batch 140, Loss: 0.752853, Memory: 352.37 MB\n",
      "Epoch 3, Batch 150, Loss: 0.800605, Memory: 352.37 MB\n",
      "Epoch 3, Batch 160, Loss: 0.818238, Memory: 352.37 MB\n",
      "Epoch 3 completed. Average Loss: 0.787458\n",
      "Epoch 4, Batch 0, Loss: 0.746010, Memory: 352.38 MB\n",
      "Epoch 4, Batch 10, Loss: 0.814373, Memory: 352.38 MB\n",
      "Epoch 4, Batch 20, Loss: 0.905948, Memory: 352.38 MB\n",
      "Epoch 4, Batch 30, Loss: 0.820336, Memory: 352.38 MB\n",
      "Epoch 4, Batch 40, Loss: 0.788838, Memory: 352.37 MB\n",
      "Epoch 4, Batch 50, Loss: 0.752293, Memory: 352.37 MB\n",
      "Epoch 4, Batch 60, Loss: 0.754196, Memory: 352.37 MB\n",
      "Epoch 4, Batch 70, Loss: 0.880498, Memory: 352.37 MB\n",
      "Epoch 4, Batch 80, Loss: 0.741546, Memory: 352.37 MB\n",
      "Epoch 4, Batch 90, Loss: 0.800768, Memory: 352.37 MB\n",
      "Epoch 4, Batch 100, Loss: 0.801450, Memory: 352.37 MB\n",
      "Epoch 4, Batch 110, Loss: 0.773212, Memory: 352.37 MB\n",
      "Epoch 4, Batch 120, Loss: 0.838761, Memory: 352.37 MB\n",
      "Epoch 4, Batch 130, Loss: 0.717576, Memory: 352.37 MB\n",
      "Epoch 4, Batch 140, Loss: 0.703996, Memory: 352.37 MB\n",
      "Epoch 4, Batch 150, Loss: 0.888220, Memory: 352.37 MB\n",
      "Epoch 4, Batch 160, Loss: 0.822463, Memory: 352.37 MB\n",
      "Epoch 4 completed. Average Loss: 0.785676\n",
      "Epoch 5, Batch 0, Loss: 0.662843, Memory: 352.38 MB\n",
      "Epoch 5, Batch 10, Loss: 0.877434, Memory: 352.38 MB\n",
      "Epoch 5, Batch 20, Loss: 0.843197, Memory: 352.38 MB\n",
      "Epoch 5, Batch 30, Loss: 0.730289, Memory: 352.38 MB\n",
      "Epoch 5, Batch 40, Loss: 0.774167, Memory: 352.37 MB\n",
      "Epoch 5, Batch 50, Loss: 0.828052, Memory: 352.37 MB\n",
      "Epoch 5, Batch 60, Loss: 0.789460, Memory: 352.37 MB\n",
      "Epoch 5, Batch 70, Loss: 0.693956, Memory: 352.37 MB\n",
      "Epoch 5, Batch 80, Loss: 0.795588, Memory: 352.37 MB\n",
      "Epoch 5, Batch 90, Loss: 0.660593, Memory: 352.37 MB\n",
      "Epoch 5, Batch 100, Loss: 0.795441, Memory: 352.37 MB\n",
      "Epoch 5, Batch 110, Loss: 0.791684, Memory: 352.37 MB\n",
      "Epoch 5, Batch 120, Loss: 0.823738, Memory: 352.37 MB\n",
      "Epoch 5, Batch 130, Loss: 0.851439, Memory: 352.37 MB\n",
      "Epoch 5, Batch 140, Loss: 0.807888, Memory: 352.37 MB\n",
      "Epoch 5, Batch 150, Loss: 0.848450, Memory: 352.37 MB\n",
      "Epoch 5, Batch 160, Loss: 0.730101, Memory: 352.37 MB\n",
      "Epoch 5 completed. Average Loss: 0.783112\n",
      "Epoch 6, Batch 0, Loss: 0.753030, Memory: 352.38 MB\n",
      "Epoch 6, Batch 10, Loss: 0.814184, Memory: 352.38 MB\n",
      "Epoch 6, Batch 20, Loss: 0.819892, Memory: 352.38 MB\n",
      "Epoch 6, Batch 30, Loss: 0.853913, Memory: 352.38 MB\n",
      "Epoch 6, Batch 40, Loss: 0.801059, Memory: 352.37 MB\n",
      "Epoch 6, Batch 50, Loss: 0.843722, Memory: 352.37 MB\n",
      "Epoch 6, Batch 60, Loss: 0.845519, Memory: 352.37 MB\n",
      "Epoch 6, Batch 70, Loss: 0.849286, Memory: 352.37 MB\n",
      "Epoch 6, Batch 80, Loss: 0.651991, Memory: 352.37 MB\n",
      "Epoch 6, Batch 90, Loss: 0.783337, Memory: 352.37 MB\n",
      "Epoch 6, Batch 100, Loss: 0.781587, Memory: 352.37 MB\n",
      "Epoch 6, Batch 110, Loss: 0.895719, Memory: 352.37 MB\n",
      "Epoch 6, Batch 120, Loss: 0.775337, Memory: 352.37 MB\n",
      "Epoch 6, Batch 130, Loss: 0.849887, Memory: 352.37 MB\n",
      "Epoch 6, Batch 140, Loss: 0.808710, Memory: 352.37 MB\n",
      "Epoch 6, Batch 150, Loss: 0.864826, Memory: 352.37 MB\n",
      "Epoch 6, Batch 160, Loss: 0.848469, Memory: 352.37 MB\n",
      "Epoch 6 completed. Average Loss: 0.781488\n",
      "Epoch 7, Batch 0, Loss: 0.746703, Memory: 352.38 MB\n",
      "Epoch 7, Batch 10, Loss: 0.813266, Memory: 352.38 MB\n",
      "Epoch 7, Batch 20, Loss: 0.751348, Memory: 352.38 MB\n",
      "Epoch 7, Batch 30, Loss: 0.807311, Memory: 352.38 MB\n",
      "Epoch 7, Batch 40, Loss: 0.700458, Memory: 352.37 MB\n",
      "Epoch 7, Batch 50, Loss: 0.633191, Memory: 352.37 MB\n",
      "Epoch 7, Batch 60, Loss: 0.760002, Memory: 352.37 MB\n",
      "Epoch 7, Batch 70, Loss: 0.781839, Memory: 352.37 MB\n",
      "Epoch 7, Batch 80, Loss: 0.772785, Memory: 352.37 MB\n",
      "Epoch 7, Batch 90, Loss: 0.748614, Memory: 352.37 MB\n",
      "Epoch 7, Batch 100, Loss: 0.883751, Memory: 352.37 MB\n",
      "Epoch 7, Batch 110, Loss: 0.763494, Memory: 352.37 MB\n",
      "Epoch 7, Batch 120, Loss: 0.761419, Memory: 352.37 MB\n",
      "Epoch 7, Batch 130, Loss: 0.816335, Memory: 352.37 MB\n",
      "Epoch 7, Batch 140, Loss: 0.699252, Memory: 352.37 MB\n",
      "Epoch 7, Batch 150, Loss: 0.856730, Memory: 352.37 MB\n",
      "Epoch 7, Batch 160, Loss: 0.701315, Memory: 352.37 MB\n",
      "Epoch 7 completed. Average Loss: 0.778092\n",
      "Epoch 8, Batch 0, Loss: 0.734843, Memory: 352.38 MB\n",
      "Epoch 8, Batch 10, Loss: 0.828108, Memory: 352.38 MB\n",
      "Epoch 8, Batch 20, Loss: 0.793579, Memory: 352.38 MB\n",
      "Epoch 8, Batch 30, Loss: 0.836791, Memory: 352.38 MB\n",
      "Epoch 8, Batch 40, Loss: 0.821282, Memory: 352.37 MB\n",
      "Epoch 8, Batch 50, Loss: 0.766974, Memory: 352.37 MB\n",
      "Epoch 8, Batch 60, Loss: 0.846479, Memory: 352.37 MB\n",
      "Epoch 8, Batch 70, Loss: 0.730747, Memory: 352.37 MB\n",
      "Epoch 8, Batch 80, Loss: 0.691637, Memory: 352.37 MB\n",
      "Epoch 8, Batch 90, Loss: 0.749943, Memory: 352.37 MB\n",
      "Epoch 8, Batch 100, Loss: 0.763977, Memory: 352.37 MB\n",
      "Epoch 8, Batch 110, Loss: 0.804985, Memory: 352.37 MB\n",
      "Epoch 8, Batch 120, Loss: 0.842208, Memory: 352.37 MB\n",
      "Epoch 8, Batch 130, Loss: 0.854012, Memory: 352.37 MB\n",
      "Epoch 8, Batch 140, Loss: 0.794041, Memory: 352.37 MB\n",
      "Epoch 8, Batch 150, Loss: 0.671133, Memory: 352.37 MB\n",
      "Epoch 8, Batch 160, Loss: 0.674140, Memory: 352.37 MB\n",
      "Epoch 8 completed. Average Loss: 0.777923\n",
      "Epoch 9, Batch 0, Loss: 0.824976, Memory: 352.38 MB\n",
      "Epoch 9, Batch 10, Loss: 0.809261, Memory: 352.38 MB\n",
      "Epoch 9, Batch 20, Loss: 0.787239, Memory: 352.38 MB\n",
      "Epoch 9, Batch 30, Loss: 0.786799, Memory: 352.38 MB\n",
      "Epoch 9, Batch 40, Loss: 0.701594, Memory: 352.37 MB\n",
      "Epoch 9, Batch 50, Loss: 0.763866, Memory: 352.37 MB\n",
      "Epoch 9, Batch 60, Loss: 0.900570, Memory: 352.37 MB\n",
      "Epoch 9, Batch 70, Loss: 0.817831, Memory: 352.37 MB\n",
      "Epoch 9, Batch 80, Loss: 0.851215, Memory: 352.37 MB\n",
      "Epoch 9, Batch 90, Loss: 0.813607, Memory: 352.37 MB\n",
      "Epoch 9, Batch 100, Loss: 0.831170, Memory: 352.37 MB\n",
      "Epoch 9, Batch 110, Loss: 0.733528, Memory: 352.37 MB\n",
      "Epoch 9, Batch 120, Loss: 0.651224, Memory: 352.37 MB\n",
      "Epoch 9, Batch 130, Loss: 0.531477, Memory: 352.37 MB\n",
      "Epoch 9, Batch 140, Loss: 0.786238, Memory: 352.37 MB\n",
      "Epoch 9, Batch 150, Loss: 0.729345, Memory: 352.37 MB\n",
      "Epoch 9, Batch 160, Loss: 0.781923, Memory: 352.37 MB\n",
      "Epoch 9 completed. Average Loss: 0.780099\n",
      "Epoch 10, Batch 0, Loss: 0.870853, Memory: 352.38 MB\n",
      "Epoch 10, Batch 10, Loss: 0.757477, Memory: 352.38 MB\n",
      "Epoch 10, Batch 20, Loss: 0.795918, Memory: 352.38 MB\n",
      "Epoch 10, Batch 30, Loss: 0.826488, Memory: 352.38 MB\n",
      "Epoch 10, Batch 40, Loss: 0.811262, Memory: 352.37 MB\n",
      "Epoch 10, Batch 50, Loss: 0.792247, Memory: 352.37 MB\n",
      "Epoch 10, Batch 60, Loss: 0.742067, Memory: 352.37 MB\n",
      "Epoch 10, Batch 70, Loss: 0.799343, Memory: 352.37 MB\n",
      "Epoch 10, Batch 80, Loss: 0.722643, Memory: 352.37 MB\n",
      "Epoch 10, Batch 90, Loss: 0.677620, Memory: 352.37 MB\n",
      "Epoch 10, Batch 100, Loss: 0.784053, Memory: 352.37 MB\n",
      "Epoch 10, Batch 110, Loss: 0.653303, Memory: 352.37 MB\n",
      "Epoch 10, Batch 120, Loss: 0.739946, Memory: 352.37 MB\n",
      "Epoch 10, Batch 130, Loss: 0.724600, Memory: 352.37 MB\n",
      "Epoch 10, Batch 140, Loss: 0.698432, Memory: 352.37 MB\n",
      "Epoch 10, Batch 150, Loss: 0.829933, Memory: 352.37 MB\n",
      "Epoch 10, Batch 160, Loss: 0.820186, Memory: 352.37 MB\n",
      "Epoch 10 completed. Average Loss: 0.776726\n",
      "Epoch 11, Batch 0, Loss: 0.837159, Memory: 352.38 MB\n",
      "Epoch 11, Batch 10, Loss: 0.798015, Memory: 352.38 MB\n",
      "Epoch 11, Batch 20, Loss: 0.779061, Memory: 352.38 MB\n",
      "Epoch 11, Batch 30, Loss: 0.680273, Memory: 352.38 MB\n",
      "Epoch 11, Batch 40, Loss: 0.694289, Memory: 352.37 MB\n",
      "Epoch 11, Batch 50, Loss: 0.730465, Memory: 352.37 MB\n",
      "Epoch 11, Batch 60, Loss: 0.874344, Memory: 352.37 MB\n",
      "Epoch 11, Batch 70, Loss: 0.726065, Memory: 352.37 MB\n",
      "Epoch 11, Batch 80, Loss: 0.840730, Memory: 352.37 MB\n",
      "Epoch 11, Batch 90, Loss: 0.757576, Memory: 352.37 MB\n",
      "Epoch 11, Batch 100, Loss: 0.679972, Memory: 352.37 MB\n",
      "Epoch 11, Batch 110, Loss: 0.771936, Memory: 352.37 MB\n",
      "Epoch 11, Batch 120, Loss: 0.766888, Memory: 352.37 MB\n",
      "Epoch 11, Batch 130, Loss: 0.816734, Memory: 352.37 MB\n",
      "Epoch 11, Batch 140, Loss: 0.705323, Memory: 352.37 MB\n",
      "Epoch 11, Batch 150, Loss: 0.746217, Memory: 352.37 MB\n",
      "Epoch 11, Batch 160, Loss: 0.852325, Memory: 352.37 MB\n",
      "Epoch 11 completed. Average Loss: 0.774214\n",
      "Epoch 12, Batch 0, Loss: 0.850672, Memory: 352.38 MB\n",
      "Epoch 12, Batch 10, Loss: 0.653425, Memory: 352.38 MB\n",
      "Epoch 12, Batch 20, Loss: 0.863424, Memory: 352.38 MB\n",
      "Epoch 12, Batch 30, Loss: 0.889294, Memory: 352.38 MB\n",
      "Epoch 12, Batch 40, Loss: 0.836546, Memory: 352.37 MB\n",
      "Epoch 12, Batch 50, Loss: 0.808304, Memory: 352.37 MB\n",
      "Epoch 12, Batch 60, Loss: 0.875676, Memory: 352.37 MB\n",
      "Epoch 12, Batch 70, Loss: 0.770747, Memory: 352.37 MB\n",
      "Epoch 12, Batch 80, Loss: 0.743658, Memory: 352.37 MB\n",
      "Epoch 12, Batch 90, Loss: 0.782034, Memory: 352.37 MB\n",
      "Epoch 12, Batch 100, Loss: 0.799960, Memory: 352.37 MB\n",
      "Epoch 12, Batch 110, Loss: 0.846014, Memory: 352.37 MB\n",
      "Epoch 12, Batch 120, Loss: 0.732784, Memory: 352.37 MB\n",
      "Epoch 12, Batch 130, Loss: 0.781716, Memory: 352.37 MB\n",
      "Epoch 12, Batch 140, Loss: 0.794923, Memory: 352.37 MB\n",
      "Epoch 12, Batch 150, Loss: 0.768244, Memory: 352.37 MB\n",
      "Epoch 12, Batch 160, Loss: 0.830108, Memory: 352.37 MB\n",
      "Epoch 12 completed. Average Loss: 0.771483\n",
      "Epoch 13, Batch 0, Loss: 0.699089, Memory: 352.38 MB\n",
      "Epoch 13, Batch 10, Loss: 0.650146, Memory: 352.38 MB\n",
      "Epoch 13, Batch 20, Loss: 0.817004, Memory: 352.38 MB\n",
      "Epoch 13, Batch 30, Loss: 0.602020, Memory: 352.38 MB\n",
      "Epoch 13, Batch 40, Loss: 0.838365, Memory: 352.37 MB\n",
      "Epoch 13, Batch 50, Loss: 0.755777, Memory: 352.37 MB\n",
      "Epoch 13, Batch 60, Loss: 0.891875, Memory: 352.37 MB\n",
      "Epoch 13, Batch 70, Loss: 0.754059, Memory: 352.37 MB\n",
      "Epoch 13, Batch 80, Loss: 0.727322, Memory: 352.37 MB\n",
      "Epoch 13, Batch 90, Loss: 0.767809, Memory: 352.37 MB\n",
      "Epoch 13, Batch 100, Loss: 0.828400, Memory: 352.37 MB\n",
      "Epoch 13, Batch 110, Loss: 0.698484, Memory: 352.34 MB\n",
      "Epoch 13, Batch 120, Loss: 0.796602, Memory: 352.34 MB\n",
      "Epoch 13, Batch 130, Loss: 0.760886, Memory: 352.34 MB\n",
      "Epoch 13, Batch 140, Loss: 0.739234, Memory: 352.34 MB\n",
      "Epoch 13, Batch 150, Loss: 0.749197, Memory: 352.34 MB\n",
      "Epoch 13, Batch 160, Loss: 0.834368, Memory: 352.34 MB\n",
      "Epoch 13 completed. Average Loss: 0.770270\n",
      "Epoch 14, Batch 0, Loss: 0.769098, Memory: 352.34 MB\n",
      "Epoch 14, Batch 10, Loss: 0.803908, Memory: 352.34 MB\n",
      "Epoch 14, Batch 20, Loss: 0.832559, Memory: 352.34 MB\n",
      "Epoch 14, Batch 30, Loss: 0.699260, Memory: 352.34 MB\n",
      "Epoch 14, Batch 40, Loss: 0.706478, Memory: 352.34 MB\n",
      "Epoch 14, Batch 50, Loss: 0.767767, Memory: 352.34 MB\n",
      "Epoch 14, Batch 60, Loss: 0.788013, Memory: 352.34 MB\n",
      "Epoch 14, Batch 70, Loss: 0.709710, Memory: 352.34 MB\n",
      "Epoch 14, Batch 80, Loss: 0.699070, Memory: 352.34 MB\n",
      "Epoch 14, Batch 90, Loss: 0.872095, Memory: 352.34 MB\n",
      "Epoch 14, Batch 100, Loss: 0.807596, Memory: 352.34 MB\n",
      "Epoch 14, Batch 110, Loss: 0.807775, Memory: 352.34 MB\n",
      "Epoch 14, Batch 120, Loss: 0.815666, Memory: 352.34 MB\n",
      "Epoch 14, Batch 130, Loss: 0.822121, Memory: 352.34 MB\n",
      "Epoch 14, Batch 140, Loss: 0.707435, Memory: 352.34 MB\n",
      "Epoch 14, Batch 150, Loss: 0.745239, Memory: 352.34 MB\n",
      "Epoch 14, Batch 160, Loss: 0.788923, Memory: 352.34 MB\n",
      "Epoch 14 completed. Average Loss: 0.769487\n",
      "Epoch 15, Batch 0, Loss: 0.652488, Memory: 352.34 MB\n",
      "Epoch 15, Batch 10, Loss: 0.747049, Memory: 352.34 MB\n",
      "Epoch 15, Batch 20, Loss: 0.674968, Memory: 352.34 MB\n",
      "Epoch 15, Batch 30, Loss: 0.707785, Memory: 352.34 MB\n",
      "Epoch 15, Batch 40, Loss: 0.764245, Memory: 352.34 MB\n",
      "Epoch 15, Batch 50, Loss: 0.742166, Memory: 352.34 MB\n",
      "Epoch 15, Batch 60, Loss: 0.709977, Memory: 352.34 MB\n",
      "Epoch 15, Batch 70, Loss: 0.812608, Memory: 352.34 MB\n",
      "Epoch 15, Batch 80, Loss: 0.727764, Memory: 352.34 MB\n",
      "Epoch 15, Batch 90, Loss: 0.762108, Memory: 352.34 MB\n",
      "Epoch 15, Batch 100, Loss: 0.815220, Memory: 352.34 MB\n",
      "Epoch 15, Batch 110, Loss: 0.703804, Memory: 352.34 MB\n",
      "Epoch 15, Batch 120, Loss: 0.699583, Memory: 352.34 MB\n",
      "Epoch 15, Batch 130, Loss: 0.857342, Memory: 352.34 MB\n",
      "Epoch 15, Batch 140, Loss: 0.832768, Memory: 352.34 MB\n",
      "Epoch 15, Batch 150, Loss: 0.734516, Memory: 352.34 MB\n",
      "Epoch 15, Batch 160, Loss: 0.751689, Memory: 352.34 MB\n",
      "Epoch 15 completed. Average Loss: 0.769170\n",
      "Epoch 16, Batch 0, Loss: 0.825387, Memory: 352.34 MB\n",
      "Epoch 16, Batch 10, Loss: 0.737462, Memory: 352.34 MB\n",
      "Epoch 16, Batch 20, Loss: 0.716975, Memory: 352.34 MB\n",
      "Epoch 16, Batch 30, Loss: 0.765111, Memory: 352.34 MB\n",
      "Epoch 16, Batch 40, Loss: 0.746549, Memory: 352.34 MB\n",
      "Epoch 16, Batch 50, Loss: 0.729942, Memory: 352.34 MB\n",
      "Epoch 16, Batch 60, Loss: 0.799867, Memory: 352.34 MB\n",
      "Epoch 16, Batch 70, Loss: 0.674345, Memory: 352.34 MB\n",
      "Epoch 16, Batch 80, Loss: 0.829934, Memory: 352.34 MB\n",
      "Epoch 16, Batch 90, Loss: 0.768175, Memory: 352.34 MB\n",
      "Epoch 16, Batch 100, Loss: 0.677575, Memory: 352.34 MB\n",
      "Epoch 16, Batch 110, Loss: 0.852512, Memory: 352.34 MB\n",
      "Epoch 16, Batch 120, Loss: 0.875063, Memory: 352.34 MB\n",
      "Epoch 16, Batch 130, Loss: 0.852592, Memory: 352.34 MB\n",
      "Epoch 16, Batch 140, Loss: 0.749075, Memory: 352.34 MB\n",
      "Epoch 16, Batch 150, Loss: 0.859395, Memory: 352.34 MB\n",
      "Epoch 16, Batch 160, Loss: 0.778436, Memory: 352.34 MB\n",
      "Epoch 16 completed. Average Loss: 0.768043\n",
      "Epoch 17, Batch 0, Loss: 0.669178, Memory: 352.34 MB\n",
      "Epoch 17, Batch 10, Loss: 0.784247, Memory: 352.34 MB\n",
      "Epoch 17, Batch 20, Loss: 0.631961, Memory: 352.34 MB\n",
      "Epoch 17, Batch 30, Loss: 0.866589, Memory: 352.34 MB\n",
      "Epoch 17, Batch 40, Loss: 0.775882, Memory: 352.34 MB\n",
      "Epoch 17, Batch 50, Loss: 0.812356, Memory: 352.34 MB\n",
      "Epoch 17, Batch 60, Loss: 0.838253, Memory: 352.34 MB\n",
      "Epoch 17, Batch 70, Loss: 0.789977, Memory: 352.34 MB\n",
      "Epoch 17, Batch 80, Loss: 0.686159, Memory: 352.34 MB\n",
      "Epoch 17, Batch 90, Loss: 0.721387, Memory: 352.34 MB\n",
      "Epoch 17, Batch 100, Loss: 0.651791, Memory: 352.34 MB\n",
      "Epoch 17, Batch 110, Loss: 0.837819, Memory: 352.34 MB\n",
      "Epoch 17, Batch 120, Loss: 0.818232, Memory: 352.34 MB\n",
      "Epoch 17, Batch 130, Loss: 0.805348, Memory: 352.34 MB\n",
      "Epoch 17, Batch 140, Loss: 0.715872, Memory: 352.34 MB\n",
      "Epoch 17, Batch 150, Loss: 0.647328, Memory: 352.34 MB\n",
      "Epoch 17, Batch 160, Loss: 0.719745, Memory: 352.34 MB\n",
      "Epoch 17 completed. Average Loss: 0.765898\n",
      "Epoch 18, Batch 0, Loss: 0.653836, Memory: 352.34 MB\n",
      "Epoch 18, Batch 10, Loss: 0.820535, Memory: 352.34 MB\n",
      "Epoch 18, Batch 20, Loss: 0.705164, Memory: 352.34 MB\n",
      "Epoch 18, Batch 30, Loss: 0.683413, Memory: 352.34 MB\n",
      "Epoch 18, Batch 40, Loss: 0.751690, Memory: 352.34 MB\n",
      "Epoch 18, Batch 50, Loss: 0.891353, Memory: 352.34 MB\n",
      "Epoch 18, Batch 60, Loss: 0.678994, Memory: 352.34 MB\n",
      "Epoch 18, Batch 70, Loss: 0.819745, Memory: 352.34 MB\n",
      "Epoch 18, Batch 80, Loss: 0.808457, Memory: 352.34 MB\n",
      "Epoch 18, Batch 90, Loss: 0.796207, Memory: 352.34 MB\n",
      "Epoch 18, Batch 100, Loss: 0.867897, Memory: 352.34 MB\n",
      "Epoch 18, Batch 110, Loss: 0.745931, Memory: 352.34 MB\n",
      "Epoch 18, Batch 120, Loss: 0.795567, Memory: 352.34 MB\n",
      "Epoch 18, Batch 130, Loss: 0.843575, Memory: 352.34 MB\n",
      "Epoch 18, Batch 140, Loss: 0.772016, Memory: 352.34 MB\n",
      "Epoch 18, Batch 150, Loss: 0.802447, Memory: 352.34 MB\n",
      "Epoch 18, Batch 160, Loss: 0.785310, Memory: 352.34 MB\n",
      "Epoch 18 completed. Average Loss: 0.764867\n",
      "Epoch 19, Batch 0, Loss: 0.697066, Memory: 352.34 MB\n",
      "Epoch 19, Batch 10, Loss: 0.845419, Memory: 352.34 MB\n",
      "Epoch 19, Batch 20, Loss: 0.861730, Memory: 352.34 MB\n",
      "Epoch 19, Batch 30, Loss: 0.826813, Memory: 352.34 MB\n",
      "Epoch 19, Batch 40, Loss: 0.755348, Memory: 352.34 MB\n",
      "Epoch 19, Batch 50, Loss: 0.800926, Memory: 352.34 MB\n",
      "Epoch 19, Batch 60, Loss: 0.784448, Memory: 352.34 MB\n",
      "Epoch 19, Batch 70, Loss: 0.654203, Memory: 352.34 MB\n",
      "Epoch 19, Batch 80, Loss: 0.697836, Memory: 352.34 MB\n",
      "Epoch 19, Batch 90, Loss: 0.824601, Memory: 352.34 MB\n",
      "Epoch 19, Batch 100, Loss: 0.704844, Memory: 352.34 MB\n",
      "Epoch 19, Batch 110, Loss: 0.717997, Memory: 352.34 MB\n",
      "Epoch 19, Batch 120, Loss: 0.769971, Memory: 352.34 MB\n",
      "Epoch 19, Batch 130, Loss: 0.729245, Memory: 352.34 MB\n",
      "Epoch 19, Batch 140, Loss: 0.828580, Memory: 352.34 MB\n",
      "Epoch 19, Batch 150, Loss: 0.798422, Memory: 352.34 MB\n",
      "Epoch 19, Batch 160, Loss: 0.825676, Memory: 352.34 MB\n",
      "Epoch 19 completed. Average Loss: 0.763150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Starting Training ===\")\n",
    "from Training import train_with_progress, train_with_memory_monitoring, simple_train\n",
    "# Pilih salah satu metode training:\n",
    "trained_model = train_with_memory_monitoring(autoencoder, dataloader, epochs=20, modelSelected=modelSelected)\n",
    "# trained_model = simple_train(autoencoder, dataloader, epochs=2)\n",
    "# trained_model = train_with_progress(autoencoder, dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf463af",
   "metadata": {},
   "source": [
    "### # Simpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03679650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.save(trained_model.state_dict(), f'../data/models/{modelSelected}_autoencoder_final.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f8215",
   "metadata": {},
   "source": [
    "### # Test reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d79b684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Reconstruction ===\n",
      "Test reconstruction loss: 0.750238\n",
      "Research completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== Testing Reconstruction ===\")\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_sample, _ = dataset[0]\n",
    "    test_sample = test_sample.unsqueeze(0)\n",
    "    encoded, decoded = trained_model(test_sample)\n",
    "    test_loss = nn.MSELoss()(decoded, test_sample)\n",
    "    print(f\"Test reconstruction loss: {test_loss.item():.6f}\")\n",
    "        \n",
    "print(\"Research completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
